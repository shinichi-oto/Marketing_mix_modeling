{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **マーケティングミックスモデリング**\n- **MMM:Marketing Mix Modeling**\n\n- この方法は、**本当に売り上げに貢献している広告は、どのドメインの広告か？**を明瞭にする方法。\n- **売上と広告媒体との関係性をモデリングし**、どの広告媒体が売り上げにどれだけの貢献、寄与しているかを分析する\n- **MMM**は、単純なこれまでの効果を分析するのではなく、今後の推移はどうなるのかという予測分析であり、**扱うデータは時系列データ**\n- **利用するデータセット**\n    - **Week**：週\n    - **Sales**：売上\n    - **TVCM**：TV CMのコスト\n    - **Newspaper**：新聞の折り込みチラシのコスト\n    - **Web**：Web広告のコスト\n- **得られる結果**\n    - **売上貢献度**\n        - **どの広告媒体が、どれだけ売上に貢献したのかを可視化**\n        - **売り上げ貢献度を計算：数理モデルを構築**\n            - **$Sales = \\beta_{0} + \\beta_{TVCM} × TVCM + \\beta_{Newspaper} × Newspaper + \\beta_{Web} × Web + \\epsilon$**\n            - ⇒　**予測モデルに使用**\n    - **ROI =（売上貢献度 － コスト）÷ コスト**\n        - **広告媒体のコストデータがあれば、ROIを可視化**\n    - **予測モデル**\n- **MMM構築パイプライン**\n    - 1. **売上を目的変数**、TVCM・Newspaper・WebCostを説明変数にモデルを構築\n    - 2. **構築したモデルを使用し**、**媒体別の売り上げ貢献度を求める**\n    - 3. 売上貢献度を足し合わせると**売上予測値**になる。この状態では実測値と乖離しているので、**補正係数を計算し、補正済みの売上貢献度を計算する**\n    - 4. **補正済みの売り上げ貢献度を使用**し、**媒体別のROIを計算**\n    \n## [**AdStockモデル(アドストックモデル)**](#AdStock)\n- **AdStock**を考慮しないモデルは**Baselineモデル**として規準にする\n- アドストック（Ad Stock）を考慮するとは、**飽和モデル(収穫逓減)**　と　**残存モデルを考慮する**\n    - **ラグ効果・残差効果・キャリーオーヴァー効果**\n    - その日だけに効果があるのではなく、次の日以降もその効果が続くということ\n- **飽和効果＋ラグ効果 = AdStock(アドストック)**\n    - 効果が遅れてくる、効果が後々まで残っている\n        - **ドメイン知**\n            - 高額商品、広告などに触れた瞬間購入ではなく、数日～の検討によって購入\n            - 消費財等の安価商品、広告に触れるうちに必要になってくる、購入したくなる場合もある。\n- **AdStockモデルでの変数の相関の対処**\n    - 広告などのマーケティング変数は、**お互いに強い相関を示すことがある**。なぜならば、同じ時期にキャンペーンという名目で広告などを投入したりする\n        - これが理由により、線形回帰モデルにとってやっかいな現象が起こることがある\n        - **対策**\n            - **正則化項付き線形回帰モデルを使用する。**\n                - [**Ridge回帰、Lasso回帰、ElasticNet**](#RLE) ⇒ 長項になるのでRidge,Lasso,ElasticNet項で説明\n            - **主成分分析回帰モデル(PCR)**\n                - [**主成分分析回帰(PCR)**](#PCR) ⇒ 主成分分析回帰項で説明\n            - **PLS回帰**\n                - [**部分的最小2乗回帰**](#PLS) ⇒ PLS項で説明\n- **AdStockモデルでの単純線形回帰モデルの問題点**\n    - ある広告にコストをかければかけるほど、**売上の上昇幅は鈍くなる**、経済学でいうところの**収穫逓減**が起こる\n    - 売上が飽和し、売上は飽和し、いくらコストをかけても売上が伸びなくなる。\n        - AdStockを考慮した線形回帰モデルで目的変数(売上)を予測するとは\n            - 広告などの説明変数のデータ（今回の例では、広告などのコスト）を**数値変換（変換器）**\n            - **線形回帰モデルの新たなインプットデータ**を作り、その**インプットデータを使い線形回帰モデルで目的変数である売上（Sales）を予測すること**\n                - **元の説明変数のデータを数値変換（変換器）** し、このデータを使い線形回帰モデルを構築する。**つまりパイプラインを構築する**\n- **AdStockを表現する関数の選定**\n    - **最適なAdStockを探索し、モデル構築する**、つまり飽和モデルとラグモデルの最適な組み合わせを探す\n    - **解釈**\n        - AdStockを表現する関数が、**違和感なく解釈可能なものかどうか**\n        - 解釈はドメイン(現場感)が重要\n    - **精度**\n        - 目的変数Y(例：売上、Sales)の**予測値と実測値が近い値になっているかどうか**というもの\n        - 機械的手法で検討する。最も精度の高いものを探索する\n- **AdStockモデルの最適な組み合わせ**\n    - **2種類のラグ効果モデルから関数を1つ**、**3種類の飽和モデルから関数を1つ選択**する\n    - [**ラグモデル**](#lag_model)\n    - [**ラグ変換器**](#lag_Converter)\n        - **定率減少型ラグモデル(Simple_CarryOver)**\n            - ピークが広告などの投入時で**徐々に低減するモデル**\n                - $x_{t}^{*}=\\displaystyle\\sum_{l=0}^{L-1}w_{t-l}・x_{t-l}, w_{t-l}=R^{l}$\n                - $x_{t}はt期の広告などの投入量で、x_{x}^{*}はt期とそれ以前までの広告などの効果の累積(残存・ラグ効果を加算蓄積)$\n                - **ハイパーパラメータ**\n                    - **L(length)**：効果の続く期間 * 当期は含まず\n                        - 期間とは、どのくらいまで考慮するか\n                    - **R(rate)**：減衰率\n        - **ピーク可変型ラグモデル(Peak_CarryOver)**\n            - ピークが広告などの投入時に**限らない**\n                - $x_{t}^{*}=\\frac{\\displaystyle\\sum_{l=0}^{L-1}w_{t-l}・x_{t-l}}{\\displaystyle\\sum_{l=0}^{L-1}w_{t-l}},w_{t-l}=R^{(l-P)^{2}}$\n                - $x_{t}はt期の広告などの投入量で、x_{x}^{*}はt期とそれ以前までの広告などの効果の累積(残存・ラグ効果を加算蓄積)$\n                - **ハイパーパラメータ**\n                    - **L(length)**：効果の続く期間　※当期含む\n                    - **P(peak)**：ピークの時期（広告などを打った日の場合は0、次期は1、など）\n                    - **R(rate)**：減衰率\n    - [**飽和モデル**](#Saturation)\n    - [**飽和変換器**](#Sat_Converter)\n        - **指数型飽和(exp_Saturation)**\n            - $x_{t}^{**}=1-e^{-\\alpha x_{t}^{*}}$\n            - $x_{t}^{*}はt期とそれ以前までの広告などの効果の蓄積(残存・ラグ効果を加算蓄積)で、x_{t}^{**}は指数型飽和モデルで変化した後のt期の値$\n        - **ロジスティック型飽和モデル(logit_Saturation)**\n            - $x_{t}^{**}=\\frac{K}{1+be^{c(c_{t}^{*}-m)}}$\n        - **ゴンペルツ型飽和モデル(gom_Saturation)**\n            - $x_{t}^{**}=Kb^{e^{-c(x_{t}^{*}-m)}}$\n- **AdStockモデルのパイプライン作成の流れ**\n    - **入力(変数) ⇒ 変換器(残差・飽和：2つの変換器) ⇒　学習器(Model) ⇒ 出力**\n        - [**変換器 : 【1】**](#AdStock_defo)\n            - **広告を打った時が効果ピーク、徐々に効果が一定の割合で減退していくモデル**\n            - **ラグ(キャリーオーバー)効果モデル**\n                - ラグ効果モデルを表現する数理モデルは複数ある。\n                - **シンプルな効果モデル：**\n                    - **広告などを打ったときが効果のピークで、徐々に効果が一定の割合で減退していくモデル**\n                        - $x_{t}^{*}=\\displaystyle\\sum_{l=0}^{L}w_{t-l}・x_{t-l}, w_{t-l}=R^{l}$\n                        - $x_{t}はt期の広告などの投入量で、x_{x}^{*}はt期とそれ以前までの広告などの効果の累積(残存・ラグ効果を加算蓄積)$\n                        - **ハイパーパラメータ**\n                            - **L(length)**：効果の続く期間 * 当期は含まず\n                                - 期間とは、どのくらいまで考慮するか\n                            - **R(rate)**：減衰率\n            - **飽和モデル**\n                - 飽和（収穫逓減）を表現する数理モデルは数存在する。\n                - **シンプルな効果モデル**\n                    - 指数関数$1-\\exp(-\\alpha x)$\n                    - ハイパーパラメータ：$\\alpha$\n            - **学習器**\n                - **(仮)線形回帰モデル**\n        - [**変換器 : 【2】**](#AdStock_logi)\n            - **効果のピークが、広告を打った時に限らないモデル**\n            - **ラグ(キャリーオーバー)効果モデル**\n                - **数理モデル**\n                - **効果モデル**\n                    - $x_{t}^{*}=\\frac{\\displaystyle\\sum_{l=0}^{L-1}w_{t-l}・x_{t-l}}{\\displaystyle\\sum_{l=0}^{L-1}w_{t-1}}, w_{t-l}=R^{(l-P)^{2}}$\n                    - $x_{t}$は$t$期の広告などの投入量で、$x_{t}^{*}$は$t$期とそれ以前までの広告などの効果の累積(残存・ラグ効果を加算蓄積)\n                    - **ハイパーパラメータ**\n                        - **L(length)**：効果の続く期間　※当期含む\n                        - **P(peak)**：ピークの時期（広告などを打った日の場合は0、次期は1、など）\n                        - **R(rate)**：減衰率\n            - **飽和モデル**\n                - **S字曲線を表現する関数：シグモイド関数、ロジスティック曲線、ゴンペルツ曲線**\n                - **ロジスティック曲線でのモデル**\n                    - $y=\\frac{K}{1+be^{c(x-m)}}$\n                        - **K**：上限パラメータ\n                        - **b**：形状パラメータ\n                        - **c**：形状パラメータ\n                        - **m**：位置パラメータ","metadata":{}},{"cell_type":"markdown","source":"- [参照サイト２](https://www.salesanalytics.co.jp/datascience/datascience099/)\n- [参照サイト３](https://www.salesanalytics.co.jp/datascience/datascience100/)\n- [参照サイト４](https://www.salesanalytics.co.jp/datascience/datascience119/)\n- [参照サイト５：主成分分析回帰(PCR)](https://www.salesanalytics.co.jp/datascience/datascience122/).\n- [参照サイト６：部分的最小2乗回帰(PLS)](https://www.salesanalytics.co.jp/datascience/datascience136/)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n\n# Model\nfrom sklearn.linear_model import LinearRegression\n\n# CV,SPLIT\nfrom sklearn.model_selection import cross_val_score, TimeSeriesSplit\n\n# plot\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot') #グラフスタイル\nplt.rcParams['figure.figsize'] = [16, 9] # グラフサイズ\n\n\n# Plot設定：指数表記なし\nnp.set_printoptions(precision=3,suppress=True)\npd.options.display.float_format = '{:.3f}'.format","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DataLoad\nurl = 'https://www.salesanalytics.co.jp/4zdt'\ndf = pd.read_csv(url,\n                 parse_dates=['Week'],\n                 index_col='Week'\n                )\n\n# データの確認\nprint(df.info()) #変数の情報\nprint(df.head())\n\n# 説明変数Xと目的変数yに分解\nX = df.drop(columns=['Sales']) \ny = df['Sales']\n\n# グラフ化\ny.plot()\nX.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **モデル構築**","metadata":{}},{"cell_type":"code","source":"linearr = LinearRegression() # DF","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- どの程度の予測精度を持ったモデルかを見る為に、**時系列におけるCV**を行う。**これをBaselineとする**\n- デフォルト５：CVの結果（決定係数$R^{2}$）の平均値\n    - **⇒　全てのデータを使用してモデルを構築する**","metadata":{}},{"cell_type":"code","source":"# CV精度検証\nnp.mean(cross_val_score(linearr, X, y, \n                        cv=TimeSeriesSplit())\n       )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# モデルの学習\nlinearr.fit(X, y)\n\n# データフレーム化\nweights = pd.Series(linearr.coef_, index=X.columns)\n\n\nprint('Intercept:\\n', linearr.intercept_, sep='') # 切片\nprint('\\n')\nprint('Coefficients:\\n',weights, sep='') # 係数","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **売上貢献度のを計算(補正前)**","metadata":{}},{"cell_type":"code","source":"# 貢献度（補正前）\nunadj_contribution = X.mul(weights) #Xと係数を乗算\n\nunadj_contribution = unadj_contribution.assign(Base=linearr.intercept_) #切片の追加\nunadj_contribution.head() #確認","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **週ごとに各媒体の売上貢献度を合計**\n    - **売上の予測値**と**元の売上の実測値**","metadata":{}},{"cell_type":"code","source":"# 貢献度の合計（yの予測値）\ny_pred = unadj_contribution.sum(axis=1)\n\nprint('予測値　\\n', y_pred.head())\nprint('テスト　\\n', y.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **乖離をなくすために、補正係数（correction factor）を計算し、売上貢献度を補正**\n- **補正係数**を計算する","metadata":{}},{"cell_type":"code","source":"# 補正係数\ncorrection_factor = y.div(y_pred, axis=0)\ncorrection_factor.head() #確認","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **補正係数を使い、売上貢献度を補正**","metadata":{}},{"cell_type":"code","source":"# 貢献度（補正後）\nadj_contribution = (unadj_contribution\n                    .mul(correction_factor, axis=0)\n                   ) \n\n# 順番の変更\nadj_contribution = adj_contribution[['Base', 'Web', 'Newspaper', 'TVCM']]\n\n#確認\nadj_contribution.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **週×媒体別の売上貢献度が求められた**\n    - 積み上げグラフで可視化","metadata":{}},{"cell_type":"code","source":"# グラフ化\nax = (adj_contribution\n      .plot.area(\n          figsize=(16, 10),\n          linewidth=0,\n          ylabel='Sales',\n          xlabel='Date')\n     )\n\n\nhandles, labels = ax.get_legend_handles_labels()\nax.legend(handles[::-1], labels[::-1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 媒体別に全ての週の売上貢献度を合計し、媒体別の売上貢献度（円と構成比％）\n- **何がどれほど売上に貢献したのか**","metadata":{}},{"cell_type":"code","source":"# 媒体別の貢献度の合計\ncontribution_sum = adj_contribution.sum(axis=0)\n#集計結果\nprint('売上貢献度（円）:\\n', \n      contribution_sum, \n      sep=''\n     )\nprint()\nprint('売上貢献度（構成比）:\\n', \n      contribution_sum/contribution_sum.sum(), \n      sep=''\n     )\n#グラフ化\ncontribution_sum.plot.pie(fontsize=24)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **費用対効果**\n    - **媒体別のコストを集計し、媒体別にROIを計算**","metadata":{}},{"cell_type":"code","source":"# 各媒体のコストの合計\ncost_sum = X.sum(axis=0)\ncost_sum #確認","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 先程求めた売上貢献度を使い、**媒体別のROIを計算しグラフ化**","metadata":{}},{"cell_type":"code","source":"# 各媒体のROIの計算\nROI = (contribution_sum.drop('Base', axis=0) - cost_sum)/cost_sum\n\n#確認\nprint('ROI:\\n', ROI, sep='')\n\n# グラフ化\nROI.plot.bar(fontsize=24)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **ROIは、値が大きいほど良く、最低限プラスの値である必要があります。** \n    - **Web広告以外はあまり良くない**ことが分かる\n- **【注意】このモデルには、ある致命的な欠陥があります。アドストック（Ad Stock）を考慮していない**\n    - **アドストック（Ad Stock）を考慮**したモデルにした方がいい\n        - **アドストック（Ad Stock）を考慮**するとは、**残存効果を考慮する**ということ\n            - **ある日の広告宣伝活動が、その日だけに効果があるのではなく、次の日以降もその効果が続くということ**です。キャリーオーバー（CarryOver）効果と表現されることもある","metadata":{}},{"cell_type":"markdown","source":"***\n<a id=\"AdStock_defo\"></a>\n# <p>**AdStockモデル構築 : Def**</p>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n\nfrom scipy.signal import convolve2d\n\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score, TimeSeriesSplit\nfrom sklearn import set_config\n\n# model\nfrom sklearn.linear_model import LinearRegression\n\n# Optuna\nfrom optuna.integration import OptunaSearchCV\nfrom optuna.distributions import UniformDistribution, IntUniformDistribution, FloatDistribution, IntDistribution, CategoricalDistribution\n\n# Plot\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nplt.rcParams['figure.figsize'] = [16, 9]\n\n#plot: 設定: 指数表記\nnp.set_printoptions(precision=3,suppress=True)\npd.options.display.float_format = '{:.3f}'.format","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DataLoad\nurl = 'https://www.salesanalytics.co.jp/4zdt'\ndf = pd.read_csv(url,\n                 parse_dates=['Week'],\n                 index_col='Week'\n                )\n\n# \nprint(df.info())\nprint(df.head()) \n\n\n# 説明変数Xと目的変数yに分解\nX = df.drop(columns=['Sales'])\ny = df['Sales']\n\n\n# グラフ化\ny.plot()\nX.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **Baseline**\n- **アドストックを考慮しない線形回帰モデル**を構築する\n- **予測精度の確認 ： 時系列のCV**を実施","metadata":{}},{"cell_type":"code","source":"# 線形回帰モデルのインスタンス\nlr = LinearRegression()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# クロスバリデーションで精度検証（R2）\nnp.mean(cross_val_score(lr, \n                        X, y, \n                        cv=TimeSeriesSplit()\n                       )\n       )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 全データで精度検証（R2）\nlr.fit(X, y)\nlr.score(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **アドストック関数**\n- **２つのモデル(変換器)の関数**を定義しAdStockを表現\n    - **飽和モデル**\n        - 指数関数$1-\\exp(-\\alpha x)$\n        - ハイパーパラメータ : $\\alpha$\n    - **ラグ効果モデル(CaryOverModel)**\n        - ハイパーパラメータ : **減退率$(rate)$** **期間$(length)$**\n- [**参照サイト**](https://www.salesanalytics.co.jp/datascience/datascience098/)","metadata":{}},{"cell_type":"code","source":"# 飽和モデル : 指数関数 1 - exp(-αx)\ndef Saturation(X, a):\n    return 1 - np.exp(-a * X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ラグ効果モデル\ndef Carryover(X: np.ndarray, rate, length):\n    filter = (rate ** np.arange(length + 1)).reshape(-1, 1) \n    convolution = convolve2d(X, filter)\n    if length > 0 : convolution = convolution[: -length]\n    return convolution","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **飽和モデル**","metadata":{}},{"cell_type":"code","source":"exp_dat = pd.DataFrame(range(500))\nexp_sat = pd.DataFrame(index=exp_dat.index)\n\nexp_sat['a=0.01'] = Saturation(exp_dat,0.01) \nexp_sat['a=0.02'] = Saturation(exp_dat,0.02) \nexp_sat['a=0.1'] = Saturation(exp_dat,0.1) \n\nprint(exp_sat)\n\nexp_sat.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **残差効果モデル**\n- 最初100でその後0であるシンプルなケースの、この関数の実行例","metadata":{}},{"cell_type":"code","source":"# Sample\nexp_dat = pd.DataFrame([100,0,0,0,0,0,0,0,0,0]) \n\n# 残差\nexp_co = Carryover(exp_dat, 0.5,2) \n\nprint(exp_co) #数値出力\nplt.bar(exp_dat.index,exp_co[:,0]) #グラフ\nplt.title('rate=0.5, length=2')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 先程の例よりも複雑なケースで、この関数の実行例\n- サンプルデータ作成","metadata":{}},{"cell_type":"code","source":"# サンプルデータ\nexp_dat = pd.DataFrame([10,500,10,500])  #入力データ\nprint(exp_dat) #数値出力\nplt.bar(exp_dat.index,exp_dat.values[:,0]) #グラフ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- サンプルデータに対し、この関数の実行","metadata":{}},{"cell_type":"code","source":"exp_co = Carryover(exp_dat, 0.5,2)\n\nprint(exp_co) #数値出力\nplt.bar(exp_dat.index,exp_co[:,0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 飽和モデルや、ラグ効果モデルを単体で使用するのではない\n    - ⇒ 変数(入力) ⇒ ラグモデル ⇒ ラグモデル(出力) ⇒ 飽和モデル ⇒ 飽和モデル(出力) ⇒ モデル\n    - 入力データ→飽和モデル→キャリーオーバー効果モデル→学習器のインプット","metadata":{}},{"cell_type":"code","source":"# 「入力→ラグ効果モデル→飽和モデル→出力」の例\nexp_sat_co = Saturation(Carryover(exp_dat, 0.5,2),0.01)\n\nprint(exp_sat_co) #数値出力\nplt.bar(exp_dat.index,exp_sat_co[:,0]) #グラフ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **アドストックを考慮した線形回帰モデル**\n- **ハイパーパラメータ**の設定","metadata":{}},{"cell_type":"code","source":"# TVCMのハイパーパラメータの設定\nTVCM_carryover_rate = 0.5\nTVCM_carryover_length = 4\nTVCM_saturation_a = 0.000002\n\n# Newspaperのハイパーパラメータの設定\nNewspaper_carryover_rate = 0.5\nNewspaper_carryover_length = 2\nNewspaper_saturation_a = 0.000002\n\n# Webのハイパーパラメータの設定\nWeb_carryover_rate = 0.5\nWeb_carryover_length = 0\nWeb_saturation_a = 0.000002","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **どのようなキャリーオーバー効果なのか**","metadata":{}},{"cell_type":"code","source":"# キャリーオーバー効果モデルの出力例\n## Sample Data\nexp_dat = pd.DataFrame([100,0,0,0,0,0,0,0,0,0]) \n\n## ------------------------------------------\n## キャリーオーバー効果\n### TVCM\nexp_co_TVCM= Carryover(\n    exp_dat, \n    TVCM_carryover_rate,\n    TVCM_carryover_length\n) \n### Newspaper\nexp_co_Newspaper = Carryover(\n    exp_dat,   \n    Newspaper_carryover_rate,\n    Newspaper_carryover_length\n) \n### Web\nexp_co_Web = Carryover(\n    exp_dat,    \n    Web_carryover_rate,\n    Web_carryover_length\n) \n## -----------------------------------------\n\n## グラフ\nfig, axes = plt.subplots(nrows=1, ncols=3, sharex=False)\n### TVCM\naxes[0].bar(exp_dat.index,\n            exp_co_TVCM[:,0]\n           ) \naxes[0].set_title('TVCM')\n### Newspaper\naxes[1].bar(exp_dat.index,\n            exp_co_Newspaper[:,0]\n           ) \naxes[1].set_title('Newspaper')\n### Web\naxes[2].bar(exp_dat.index,\n            exp_co_Web[:,0]\n           ) \naxes[2].set_title('Web')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 説明変数X（広告などのコスト）のデータに対し、**ラグ効果モデル**と**飽和モデル**を使い、**学習器（線形回帰モデル）のインプット**を作る","metadata":{}},{"cell_type":"code","source":"# TVの値の変換\nX_TVCM = Saturation(Carryover(X[['TVCM']],\n                            TVCM_carryover_rate,\n                            TVCM_carryover_length),\n                  TVCM_saturation_a)\n# Newspaperの値の変換\nX_Newspaper = Saturation(Carryover(X[['Newspaper']], \n                               Newspaper_carryover_rate,\n                               Newspaper_carryover_length),\n                     Newspaper_saturation_a)\n# Webの値の変換\nX_Web = Saturation(Carryover(X[['Web']], \n                                 Web_carryover_rate,\n                                 Web_carryover_length),\n                       Web_saturation_a)\n# 変換した値の結合（DataFrame型へ）\nX_trans = pd.DataFrame(np.concatenate([X_TVCM, \n                                       X_Newspaper,\n                                       X_Web], \n                                      1))\n\nX_trans.columns = ['TVCM','Newspaper','Web']\nX_trans #確認","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- この説明変数Xを変換し作ったデータを使い、**線形回帰モデルを作り精度検証**\n- 時系列のCV（クロスバリデーション）を実施","metadata":{}},{"cell_type":"code","source":"# クロスバリデーションで精度検証（R2）\nnp.mean(cross_val_score(lr, \n                        X_trans, y, \n                        cv=TimeSeriesSplit()\n                       )\n       )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 全データで精度検証（R2）\nlr.fit(X_trans, y)\nlr.score(X_trans, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **アドストックを考慮した線形回帰モデル（Optunaでハイパーパラメータチューニング）**\n- **変換器と学習器を繋いだパイプライン**を作り、**Optunaでハイパーパラメータ探索**を実施し**最適なモデル**を作る\n\n## **パイプライン構築**\n- **飽和モデル**と**ラグ効果モデル**を、**パイプラインで利用できる変換器**","metadata":{}},{"cell_type":"code","source":"# Pipeline用変換器（飽和モデル）\nclass ExponentialSaturation(BaseEstimator, TransformerMixin):\n    \n    # 初期化\n    def __init__(self, a=1.0):\n        self.a = a #ハイパーパラメータ\n    \n    # 学習\n    def fit(self, X, y=None):\n        return self\n    \n    # 処理（入力→出力）\n    def transform(self, X):\n        return Saturation(X,self.a)\n    \n\n# Pipeline用変換器（ラグ効果モデル）\nclass ExponentialCarryover(BaseEstimator, TransformerMixin):\n    \n    # 初期化\n    def __init__(self, rate=0.5, length=1):\n        self.rate = rate #ハイパーパラメータ\n        self.length = length #ハイパーパラメータ\n        \n    # 学習        \n    def fit(self, X, y=None):\n        return self\n    \n    # 処理（入力→出力）\n    def transform(self, X: np.ndarray):\n        return Carryover(X, self.rate, self.length)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **この変換器を使い、パイプラインを構築**","metadata":{}},{"cell_type":"code","source":"# Pipelineの構築\n\n## 説明変数の変換部分（adstock）の定義\nadstock = ColumnTransformer(\n    [\n     ('TVCM_pipe', Pipeline([\n                           ('carryover', ExponentialCarryover()),\n                           ('saturation', ExponentialSaturation())\n     ]), ['TVCM']),\n     ('Newspaper_pipe', Pipeline([\n                           ('carryover', ExponentialCarryover()),\n                           ('saturation', ExponentialSaturation())\n     ]), ['Newspaper']),\n     ('Web_pipe', Pipeline([\n                           ('carryover', ExponentialCarryover()),\n                           ('saturation', ExponentialSaturation())\n     ]), ['Web']),\n    ],\n    remainder='passthrough'\n)\n\n## 説明変数の変換（adstock）→線形回帰モデル（regression）\nMMM_pipe = Pipeline([\n    ('adstock', adstock),\n    ('regression', LinearRegression())\n])\n\n## パイプラインの確認\nset_config(display='diagram')   \nMMM_pipe","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **パイパーパラメータ探索の実施**\n- **パイプラインを構築**したので、**パイパーパラメータを探索**","metadata":{}},{"cell_type":"code","source":"# 探索するハイパーパラメータの設定\nparams = {\n        'adstock__TVCM_pipe__carryover__rate': FloatDistribution(0, 1),\n        'adstock__TVCM_pipe__carryover__length': IntDistribution(0, 6),\n        'adstock__TVCM_pipe__saturation__a': FloatDistribution(0, 0.01),\n        'adstock__Newspaper_pipe__carryover__rate': FloatDistribution(0, 1),\n        'adstock__Newspaper_pipe__carryover__length': IntDistribution(0, 6),\n        'adstock__Newspaper_pipe__saturation__a': FloatDistribution(0, 0.01),\n        'adstock__Web_pipe__carryover__rate': FloatDistribution(0, 1),\n        'adstock__Web_pipe__carryover__length': IntDistribution(0, 6),\n        'adstock__Web_pipe__saturation__a': FloatDistribution(0, 0.01),\n}\n# ハイパーパラメータ探索の設定\noptuna_search = OptunaSearchCV(\n    estimator=MMM_pipe,\n    param_distributions=params,\n    n_trials=1000,\n    cv=TimeSeriesSplit(),\n    random_state=0\n)\n# 探索実施\noptuna_search.fit(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 探索結果\noptuna_search.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **探索し得られたハイパーパラメータ**で、**どのようなラグ効果になるのか**を確認する","metadata":{}},{"cell_type":"code","source":"# ラグ効果モデルの出力例\n## SampleData\nexp_dat = pd.DataFrame([100,0,0,0,0,0,0,0,0,0])\n\n## ハイパーパラメータ設定 : BestParams\n### TVCM\nTVCM_carryover_rate = optuna_search.best_params_['adstock__TVCM_pipe__carryover__rate']\nTVCM_carryover_length = optuna_search.best_params_['adstock__TVCM_pipe__carryover__length']\n### Newspaper\nNewspaper_carryover_rate = optuna_search.best_params_['adstock__Newspaper_pipe__carryover__rate']\nNewspaper_carryover_length = optuna_search.best_params_['adstock__Newspaper_pipe__carryover__length']\n### Web\nWeb_carryover_rate = optuna_search.best_params_['adstock__Web_pipe__carryover__rate']\nWeb_carryover_length = optuna_search.best_params_['adstock__Web_pipe__carryover__length']\n\n\n## キャリーオーバー効果\n### TVCM\nexp_co_TVCM= Carryover(\n    exp_dat, \n    TVCM_carryover_rate,\n    TVCM_carryover_length\n) \n### Newspaper\nexp_co_Newspaper = Carryover(\n    exp_dat,   \n    Newspaper_carryover_rate,\n    Newspaper_carryover_length\n) \n### Web\nexp_co_Web = Carryover(\n    exp_dat,    \n    Web_carryover_rate,\n    Web_carryover_length\n) \n\n\n## Plot\nfig, axes = plt.subplots(nrows=1, ncols=3, sharex=False)\n\n### TVCM\naxes[0].bar(exp_dat.index,\n            exp_co_TVCM[:,0]\n           ) \naxes[0].set_title('TVCM(y:logarithmic scale)')\naxes[0].set_yscale('log')\naxes[0].set_ylim(0, 100)\n\n### Newspaper\naxes[1].bar(exp_dat.index,\n            exp_co_Newspaper[:,0]\n           ) \naxes[1].set_title('Newspaper')\n\n### Web\naxes[2].bar(exp_dat.index,\n            exp_co_Web[:,0]\n           ) \naxes[2].set_title('Web')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **最適なハイパーパラメータでパイプラインを学習**","metadata":{}},{"cell_type":"code","source":"# パイプラインのインスタンス\nMMM_pipe_best = MMM_pipe.set_params(**optuna_search.best_params_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CVで精度検証\nnp.mean(cross_val_score(MMM_pipe_best, \n                        X, y, \n                        cv=TimeSeriesSplit()\n                       )\n       )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 全データで精度検証（R2）\nMMM_pipe_best.fit(X, y)\nMMM_pipe_best.score(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- どのような線形回帰モデルなのか（切片と回帰係数）を見る","metadata":{}},{"cell_type":"code","source":"# 線形回帰モデルの切片と回帰係数\nintercept = MMM_pipe_best.named_steps['regression'].intercept_ #切片\ncoef = MMM_pipe_best.named_steps['regression'].coef_ #回帰係数\n# 回帰係数をデータフレーム化\nweights = pd.Series(\n    coef,\n    index=X.columns\n)\n# 結果出力（切片と係数）\nprint('Intercept:\\n', intercept, sep='')\nprint()\nprint('Coefficients:\\n',weights, sep='')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **売上貢献度の算出**\n- 学習し構築した**パイプラインの変換器（adstock）**を抽出","metadata":{}},{"cell_type":"code","source":"# Piplineの変換器（adstock）を抽出\nadstock = MMM_pipe_best.named_steps['adstock']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 説明変数を変換し、学習データのインプットデータを作る","metadata":{}},{"cell_type":"code","source":"# 説明変数Xの変換\nX_trans = pd.DataFrame(adstock.transform(X),\n                       index=X.\n                       index,columns=X.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 先程求めた線形回帰式を使い、売上貢献度（補正前）を計算","metadata":{}},{"cell_type":"code","source":"# 貢献度（補正前）\nunadj_contribution = X_trans.mul(weights) #Xと係数を乗算\nunadj_contribution = unadj_contribution.assign(Base=intercept) #切片の追加\n\nunadj_contribution.head() #確認","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 週ごとに各媒体の売上貢献度を合計すると、**売上の予測値**","metadata":{}},{"cell_type":"code","source":"# 貢献度の合計（yの予測値）\ny_pred = unadj_contribution.sum(axis=1)\ny_pred.head() #確認","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 元の**売上の実測値**","metadata":{}},{"cell_type":"code","source":"y.head() #確認","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **予測値と実測値が乖離**している。この乖離をなくすために、**補正係数**を計算し、**売上貢献度を補正**","metadata":{}},{"cell_type":"code","source":"# 補正係数\ncorrection_factor = y.div(y_pred, axis=0)\ncorrection_factor.head() #確認","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- この**補正係数**を使い、**売上貢献度を補正**","metadata":{}},{"cell_type":"code","source":"# 貢献度（補正後）\nadj_contribution = (unadj_contribution\n                    .mul(correction_factor, axis=0)\n                   ) \n# 順番の変更\nadj_contribution = adj_contribution[['Base', 'Web', 'Newspaper', 'TVCM']]\n#確認\nadj_contribution.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 週×媒体別の売上貢献度が求められたので、**積み上げグラフを作成**","metadata":{}},{"cell_type":"code","source":"# グラフ化\nax = (adj_contribution\n      .plot.area(\n          figsize=(16, 10),\n          linewidth=0,\n          ylabel='Sales',\n          xlabel='Date')\n     )\nhandles, labels = ax.get_legend_handles_labels()\nax.legend(handles[::-1], labels[::-1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **媒体別に全ての週の売上貢献度を合計**し、**媒体別の売上貢献度（円と構成比％）**と、そのグラフを作り、**何がどれほど売上に貢献したのか**を見る","metadata":{}},{"cell_type":"code","source":"# 媒体別の貢献度の合計\ncontribution_sum = adj_contribution.sum(axis=0)\n#集計結果\nprint('売上貢献度（円）:\\n', \n      contribution_sum, \n      sep=''\n     )\nprint()\nprint('売上貢献度（構成比）:\\n', \n      contribution_sum/contribution_sum.sum(), \n      sep=''\n     )\n#グラフ化\ncontribution_sum.plot.pie(fontsize=24)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **費用対効果**を見てみます。今回は**媒体別にROIを計算**\n- **媒体別のコスト**を集計","metadata":{}},{"cell_type":"code","source":"# 各媒体のコストの合計\ncost_sum = X.sum(axis=0)\ncost_sum #確認","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 先程求めた売上貢献度を使い、**媒体別のROIを計算しグラフ化**","metadata":{}},{"cell_type":"code","source":"# 各媒体のROIの計算\nROI = (contribution_sum.drop('Base', axis=0) - cost_sum)/cost_sum\n\n#確認\nprint('ROI:\\n', ROI, sep='')\n# グラフ化\nROI.plot.bar(fontsize=24)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- ROIは、値が大きいほど良く、最低限プラスの値である必要があります。少なくとも0以上である必要がある\n- このモデルは、**アドストック（Ad Stock）を考慮**していますが、**残差効果モデル**の作り方から分かりますが、**最初に効果のピークが来て徐々に効果が減衰するモデル**\n- 現実はそうではなく、**効果のピークが最初に来ることもあれば、数日後や数週間後にピークが来ることもあります。** そのようなモデルの方がいい\n\n- 今回は最適なハイパーパラメータを1つ探索するということをしましたが、別のハイパーパラメータの組み合わせでも同じ程度のレベルの予測精度になる可能性もあります。\n- **ハイパーパラメータを1つ**とするのではなく、ある分布の代表値として見なす考え方もあります。そのためには、**ベイズモデルでMMMを構築する**必要がある","metadata":{}},{"cell_type":"markdown","source":"***\n<a id=\"AdStock_logi\"></a>\n# <p>**AdStock :飽和モデル(ロジスティック関数)**</p>","metadata":{}},{"cell_type":"markdown","source":"### **飽和モデル**\n- **ロジスティック曲線**\n    - $y=\\frac{K}{1+be^{c(x-m)}}$\n        - **x**：データ\n        - **K**：上限パラメータ\n        - **b**：形状パラメータ\n        - **c**：形状パラメータ\n        - **m**：位置パラメータ\n        - **e**：exp","metadata":{}},{"cell_type":"code","source":"# 飽和モデル（関数）の定義\ndef Saturation(X,K,b,c,m):\n    return K/(1+b*np.exp(-c*(X-m)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 飽和モデル（関数）の例\nexp_dat = pd.DataFrame(range(100)) #入力データ\nexp_sat = pd.DataFrame(index=exp_dat.index)\nexp_sat['K=1 b=1 c=1 m=50'] = Saturation(exp_dat,1,1,1,50) \nexp_sat['K=1 b=1 c=0.1 m=50'] = Saturation(exp_dat,1,1,0.1,50) \nexp_sat['K=1 b=2 c=0.1 m=50'] = Saturation(exp_dat,1,2,0.1,50) \nexp_sat['K=1 b=1 c=0.01 m=50'] = Saturation(exp_dat,1,1,0.01,50) \nexp_sat.plot() #グラフ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **残差効果モデル**\n- **効果のピークが広告などを打った時に限らない**モデル\n- $x_{t}$期の広告などの投入量で、$x_{t}^{*}$は$t$期とそれ以前までの広告などの効果の蓄積(残差効果を足したもの)\n- **ハイパーパラメータ**\n    - **L(length)**：効果の続く期間（広告などを打った日も含む）\n    - **P(peak)**：ピークの時期（広告などを打った日の場合は0、次期は1、など）\n    - **R(rate)**：減衰率","metadata":{}},{"cell_type":"code","source":"def Carryover(X: np.ndarray, length, peak, rate):\n    X = np.append(np.zeros(length-1), X)\n    \n    Ws = np.zeros(length)\n    \n    for l in range(length):\n        W = rate**((l-peak)**2)\n        Ws[length-1-l] = W\n    \n    carryover_X = []\n    \n    for i in range(length-1, len(X)):\n        X_array = X[i-length+1:i+1]\n        Xi = sum(X_array * Ws)/sum(Ws)\n        carryover_X.append(Xi)\n        \n    return np.array(carryover_X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **ラグ効果モデル**\n- **効果のピークが広告などを打った時に限らない**モデル\n- **ハイパーパラメータ**\n    - **L(length)**：効果の続く期間（広告などを打った日も含む）\n    - **P(peak)**：ピークの時期（広告などを打った日の場合は0、次期は1、など）\n    - **R(rate)**：減衰率","metadata":{}},{"cell_type":"code","source":"def Carryover(X: np.ndarray, length, peak, rate):\n    X = np.append(np.zeros(length-1), X)\n    \n    Ws = np.zeros(length)\n    \n    for l in range(length):\n        W = rate**((l-peak)**2)\n        Ws[length-1-l] = W\n    \n    carryover_X = []\n    \n    for i in range(length-1, len(X)):\n        X_array = X[i-length+1:i+1]\n        Xi = sum(X_array * Ws)/sum(Ws)\n        carryover_X.append(Xi)\n        \n    return np.array(carryover_X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **最初100**で**その後0**であるシンプルなケースの、この関数の**実行例**","metadata":{}},{"cell_type":"code","source":"# キャリーオーバー効果モデル（関数）の例\n## サンプルデータ\nexp_dat = pd.DataFrame([100,0,0,0,0,0,0,0,0,0]) \n## キャリーオーバー効果\nexp_co = Carryover(exp_dat, 4, 1, 0.5)\nplt.bar(exp_dat.index,exp_co) #グラフ\nplt.title('length=4 peak=1 rate=0.5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **アドストックを考慮した線形回帰モデル**","metadata":{}},{"cell_type":"code","source":"# TVCMのハイパーパラメータの設定\nTVCM_carryover_length = 5\nTVCM_carryover_peak = 1\nTVCM_carryover_rate = 0.5\nTVCM_saturation_K = 1\nTVCM_saturation_b = 1\nTVCM_saturation_c = 0.1\nTVCM_saturation_m = np.mean(X.TVCM)\n\n# Newspaperのハイパーパラメータの設定\nNewspaper_carryover_length = 3\nNewspaper_carryover_peak = 0\nNewspaper_carryover_rate = 0.5\nNewspaper_saturation_K = 1\nNewspaper_saturation_b = 1\nNewspaper_saturation_c = 0.1\nNewspaper_saturation_m = np.mean(X.Newspaper)\n\n# Webのハイパーパラメータの設定\nWeb_carryover_length = 1\nWeb_carryover_peak = 0\nWeb_carryover_rate = 0.5\nWeb_saturation_K = 1\nWeb_saturation_b = 1\nWeb_saturation_c = 0.1\nWeb_saturation_m = np.mean(X.Web)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **どのようなキャリーオーバー効果なのか**","metadata":{}},{"cell_type":"code","source":"# キャリーオーバー効果モデルの出力例\n## サンプルデータ\nexp_dat = pd.DataFrame([100,0,0,0,0,0,0,0,0,0]) \n## キャリーオーバー効果\n### TVCM\nexp_co_TVCM= Carryover(\n    exp_dat, \n    TVCM_carryover_length,\n    TVCM_carryover_peak,\n    TVCM_carryover_rate\n) \n### Newspaper\nexp_co_Newspaper = Carryover(\n    exp_dat,   \n    Newspaper_carryover_length,\n    Newspaper_carryover_peak,\n    Newspaper_carryover_rate\n) \n### Web\nexp_co_Web = Carryover(\n    exp_dat,    \n    Web_carryover_length,\n    Web_carryover_peak,\n    Web_carryover_rate\n) \n## グラフ\nfig, axes = plt.subplots(nrows=1, ncols=3, sharex=False)\n### TVCM\naxes[0].bar(exp_dat.index,\n            exp_co_TVCM\n           ) \naxes[0].set_title('TVCM')\n### Newspaper\naxes[1].bar(exp_dat.index,\n            exp_co_Newspaper\n           ) \naxes[1].set_title('Newspaper')\n### Web\naxes[2].bar(exp_dat.index,\n            exp_co_Web\n           ) \naxes[2].set_title('Web')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 説明変数X（広告などのコスト）のデータに対し、**ラグ効果モデルと飽和モデル**を使い、**学習器（線形回帰モデル）のインプット**","metadata":{}},{"cell_type":"code","source":"# TVの値の変換\nX_TVCM = Saturation(Carryover(X[['TVCM']],\n                              TVCM_carryover_length,\n                              TVCM_carryover_peak,\n                              TVCM_carryover_rate).reshape(-1,1),\n                    TVCM_saturation_K,\n                    TVCM_saturation_b,\n                    TVCM_saturation_c,\n                    TVCM_saturation_m\n                   )\n# Newspaperの値の変換\nX_Newspaper = Saturation(Carryover(X[['Newspaper']], \n                              Newspaper_carryover_length,\n                              Newspaper_carryover_peak,\n                              Newspaper_carryover_rate).reshape(-1,1),\n                    Newspaper_saturation_K,\n                    Newspaper_saturation_b,\n                    Newspaper_saturation_c,\n                    Newspaper_saturation_m\n                   )\n# Webの値の変換\nX_Web = Saturation(Carryover(X[['Web']], \n                              Web_carryover_length,\n                              Web_carryover_peak,\n                              Web_carryover_rate).reshape(-1,1),\n                    Web_saturation_K,\n                    Web_saturation_b,\n                    Web_saturation_c,\n                    Web_saturation_m\n                   )\n# 変換した値の結合（DataFrame型へ）\nX_trans = pd.DataFrame(np.concatenate([X_TVCM, \n                                       X_Newspaper,\n                                       X_Web], \n                                      1))\nX_trans.columns = ['TVCM','Newspaper','Web']\nX_trans #確認","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# クロスバリデーションで精度検証（R2）\n# CV\nnp.mean(cross_val_score(lr, \n                        X_trans, y, \n                        cv=TimeSeriesSplit()\n                       )\n       )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 全データで精度検証（R2）\nlr.fit(X_trans, y)\nlr.score(X_trans, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **AdStock - Optuna - Hyperparameters**\n- 変換器と学習器を繋いだパイプライン\n- Optunaでハイパーパラメータ探索を実施し最適なモデル\n- **ハイパーパラメータ**\n    - ラグ効果モデル\n        - L(length)：効果の続く期間（広告などを打った日も含む）\n        - P(peak)：ピークの時期（広告などを打った日の場合は0、次期は1、など）\n        - R(rate)：減衰率\n    - 飽和モデル\n        - K：上限パラメータ\n        - b：形状パラメータ\n        - c：形状パラメータ\n        - m：位置パラメータ\n- **パイプライン構築**\n    - 飽和モデルとラグ効果モデルを、パイプラインで利用できる変換器","metadata":{}},{"cell_type":"code","source":"# Pipeline用変換器（飽和モデル）\nclass ExponentialSaturation(BaseEstimator, TransformerMixin):\n    \n    # 初期化\n    def __init__(self, K=1.0, b=1.0, c=0.1, m=100.0):\n        self.K = K\n        self.b = b\n        self.c = c\n        self.m = m\n    \n    # 学習\n    def fit(self, X, y=None):\n        return self\n    \n    # 処理（入力→出力）\n    def transform(self, X):\n        return Saturation(X,self.K, self.b, self.c, self.m).reshape(-1,1)\n    \n# Pipeline用変換器（キャリーオーバー効果モデル）\nclass ExponentialCarryover(BaseEstimator, TransformerMixin):\n    # 初期化\n    def __init__(self, length=4, peak=1, rate=0.5):\n        self.length = length #ハイパーパラメータ\n        self.peak = peak #ハイパーパラメータ\n        self.rate = rate #ハイパーパラメータ\n        \n    # 学習        \n    def fit(self, X, y=None):\n        return self\n    \n    # 処理（入力→出力）\n    def transform(self, X: np.ndarray):\n        return Carryover(X, self.length, self.peak, self.rate)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **パイプライン構築**","metadata":{}},{"cell_type":"code","source":"# Pipelineの構築\n## 説明変数の変換部分（adstock）の定義\nadstock = ColumnTransformer(\n    [\n     ('TVCM_pipe', Pipeline([\n                           ('carryover', ExponentialCarryover()),\n                           ('saturation', ExponentialSaturation())\n     ]), ['TVCM']),\n     ('Newspaper_pipe', Pipeline([\n                           ('carryover', ExponentialCarryover()),\n                           ('saturation', ExponentialSaturation())\n     ]), ['Newspaper']),\n     ('Web_pipe', Pipeline([\n                           ('carryover', ExponentialCarryover()),\n                           ('saturation', ExponentialSaturation())\n     ]), ['Web']),\n    ],\n    remainder='passthrough'\n)\n\n\n## 説明変数の変換（adstock）→線形回帰モデル（regression）\nMMM_pipe = Pipeline([\n    ('adstock', adstock),\n    ('regression', LinearRegression())\n])\n\n\n## パイプラインの確認\nset_config(display='diagram')   \nMMM_pipe","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **パイプラインを構築**したので、**パイパーパラメータを探索**","metadata":{}},{"cell_type":"code","source":"# ハイパーパラメータの探索の設定\nparams = {\n    'adstock__TVCM_pipe__carryover__length': IntUniformDistribution(1, 7),\n    'adstock__TVCM_pipe__carryover__peak': IntUniformDistribution(0, 2),\n    'adstock__TVCM_pipe__carryover__rate': UniformDistribution(0, 1),\n    'adstock__TVCM_pipe__saturation__K': UniformDistribution(np.min(X.TVCM), np.max(X.TVCM)),\n    'adstock__TVCM_pipe__saturation__b': UniformDistribution(0, 10),\n    'adstock__TVCM_pipe__saturation__c': UniformDistribution(0, 1),\n    'adstock__TVCM_pipe__saturation__m': UniformDistribution(np.min(X.TVCM), np.max(X.TVCM)),\n    'adstock__Newspaper_pipe__carryover__length': IntUniformDistribution(1, 7),\n    'adstock__Newspaper_pipe__carryover__peak': IntUniformDistribution(0, 2),\n    'adstock__Newspaper_pipe__carryover__rate': UniformDistribution(0, 1),\n    'adstock__Newspaper_pipe__saturation__K': UniformDistribution(np.min(X.Newspaper), np.max(X.Newspaper)),\n    'adstock__Newspaper_pipe__saturation__b': UniformDistribution(0, 10),\n    'adstock__Newspaper_pipe__saturation__c': UniformDistribution(0, 1),\n    'adstock__Newspaper_pipe__saturation__m': UniformDistribution(np.min(X.Newspaper), np.max(X.Newspaper)),\n    'adstock__Web_pipe__carryover__length': IntUniformDistribution(1, 7),\n    'adstock__Web_pipe__carryover__peak': IntUniformDistribution(0, 2),\n    'adstock__Web_pipe__carryover__rate': UniformDistribution(0, 1),\n    'adstock__Web_pipe__saturation__K': UniformDistribution(np.min(X.Web), np.max(X.Web)),\n    'adstock__Web_pipe__saturation__b': UniformDistribution(0, 10),\n    'adstock__Web_pipe__saturation__c': UniformDistribution(0, 1),\n    'adstock__Web_pipe__saturation__m': UniformDistribution(np.min(X.Web), np.max(X.Web)),\n}\n\n# ハイパーパラメータ探索の設定\noptuna_search = OptunaSearchCV(\n    estimator=MMM_pipe,\n    param_distributions=params,\n    n_trials=1000,\n    cv=TimeSeriesSplit(),\n    error_score='raise',\n    random_state=0\n)\n\n# 探索実施\noptuna_search.fit(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 探索結果\noptuna_search.best_params_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **探索し得られたハイパーパラメータ**で、どのような**ラグ効果**になるのか","metadata":{}},{"cell_type":"code","source":"# キャリーオーバー効果モデルの出力例\n## サンプルデータ\nexp_dat = pd.DataFrame([100,0,0,0,0,0,0,0,0,0]) \n\n\n## ハイパーパラメータ設定\n### TVCM\nTVCM_carryover_length = optuna_search.best_params_['adstock__TVCM_pipe__carryover__length']\nTVCM_carryover_peak = optuna_search.best_params_['adstock__TVCM_pipe__carryover__peak']\nTVCM_carryover_rate = optuna_search.best_params_['adstock__TVCM_pipe__carryover__rate']\n### Newspaper\nNewspaper_carryover_length = optuna_search.best_params_['adstock__Newspaper_pipe__carryover__length']\nNewspaper_carryover_peak = optuna_search.best_params_['adstock__Newspaper_pipe__carryover__peak']\nNewspaper_carryover_rate = optuna_search.best_params_['adstock__Newspaper_pipe__carryover__rate']\n### Web\nWeb_carryover_length = optuna_search.best_params_['adstock__Web_pipe__carryover__length']\nWeb_carryover_peak = optuna_search.best_params_['adstock__Web_pipe__carryover__peak']\nWeb_carryover_rate = optuna_search.best_params_['adstock__Web_pipe__carryover__rate']\n\n\n## キャリーオーバー効果\n### TVCM\nexp_co_TVCM= Carryover(\n    exp_dat, \n    TVCM_carryover_length,\n    TVCM_carryover_peak,\n    TVCM_carryover_rate,\n) \n### Newspaper\nexp_co_Newspaper = Carryover(\n    exp_dat,   \n    Newspaper_carryover_length,\n    Newspaper_carryover_peak,\n    Newspaper_carryover_rate,\n) \n### Web\nexp_co_Web = Carryover(\n    exp_dat,    \n    Web_carryover_length,\n    Web_carryover_peak,\n    Web_carryover_rate,\n) \n\n\n## グラフ\nfig, axes = plt.subplots(nrows=1, ncols=3, sharex=False)\n### TVCM\naxes[0].bar(exp_dat.index,\n            exp_co_TVCM\n           ) \naxes[0].set_title('TVCM(y:logarithmic scale)')\naxes[0].set_yscale('log')\naxes[0].set_ylim(0, 100)\n### Newspaper\naxes[1].bar(exp_dat.index,\n            exp_co_Newspaper\n           ) \naxes[1].set_title('Newspaper')\n### Web\naxes[2].bar(exp_dat.index,\n            exp_co_Web\n           ) \naxes[2].set_title('Web')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 最適なハイパーパラメータでパイプラインを学習\n- パイプラインのインスタンスを作成","metadata":{}},{"cell_type":"code","source":"# パイプラインのインスタンス\nMMM_pipe_best = MMM_pipe.set_params(**optuna_search.best_params_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **CV**","metadata":{}},{"cell_type":"code","source":"# クロスバリデーションで精度検証（R2）\nnp.mean(cross_val_score(MMM_pipe_best, \n                        X, y, \n                        cv=TimeSeriesSplit()\n                       )\n       )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 全データで精度検証（R2）\nMMM_pipe_best.fit(X, y)\nMMM_pipe_best.score(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 線形回帰モデルなのか（切片と回帰係数）","metadata":{}},{"cell_type":"code","source":"# 線形回帰モデルの切片と回帰係数\nintercept = MMM_pipe_best.named_steps['regression'].intercept_ #切片\ncoef = MMM_pipe_best.named_steps['regression'].coef_ #回帰係数\n# 回帰係数をデータフレーム化\nweights = pd.Series(\n    coef,\n    index=X.columns\n)\n\n# 結果出力（切片と係数）\nprint('Intercept:\\n', intercept, sep='')\nprint()\nprint('Coefficients:\\n',weights, sep='')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **売上貢献度の算出**\n- 学習し構築した**パイプラインの変換器（adstock）**を抽出","metadata":{}},{"cell_type":"code","source":"# Piplineの変換器（adstock）を抽出\nadstock = MMM_pipe_best.named_steps['adstock']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 説明変数を変換し、**学習データのインプットデータ**を作る","metadata":{}},{"cell_type":"code","source":"# 説明変数Xの変換\nX_trans = pd.DataFrame(adstock.transform(X),\n                       index=X.\n                       index,columns=X.columns)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 先程求めた線形回帰式を使い、**売上貢献度（補正前）を計算**","metadata":{}},{"cell_type":"code","source":"# 貢献度（補正前）\nunadj_contribution = X_trans.mul(weights) #Xと係数を乗算\nunadj_contribution = unadj_contribution.assign(Base=intercept) #切片の追加\nunadj_contribution.head() #確認","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 週ごとに各媒体の売上貢献度を合計すると、**売上の予測値**","metadata":{}},{"cell_type":"code","source":"# 貢献度の合計（yの予測値）\ny_pred = unadj_contribution.sum(axis=1)\ny_pred.head() #確認","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.head() #確認","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **予測値と実測値が乖離**していることが分かります。この乖離をなくすために、**補正係数（correction factor）**を計算し、**売上貢献度を補正**\n- **補正係数を計算**","metadata":{}},{"cell_type":"code","source":"# 補正係数\ncorrection_factor = y.div(y_pred, axis=0)\ncorrection_factor.head() #確認","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- この**補正係数**を使い、**売上貢献度を補正**","metadata":{}},{"cell_type":"code","source":"# 貢献度（補正後）\nadj_contribution = (unadj_contribution\n                    .mul(correction_factor, axis=0)\n                   ) \n# 順番の変更\nadj_contribution = adj_contribution[['Base', 'Web', 'Newspaper', 'TVCM']]\n#確認\nadj_contribution.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **週×媒体別の売上貢献度**が求められたので、**積み上げグラフ作成**","metadata":{}},{"cell_type":"code","source":"# グラフ化\nax = (adj_contribution\n      .plot.area(\n          figsize=(16, 10),\n          linewidth=0,\n          ylabel='Sales',\n          xlabel='Date')\n     )\nhandles, labels = ax.get_legend_handles_labels()\nax.legend(handles[::-1], labels[::-1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **媒体別に全ての週の売上貢献度を合計**し、**媒体別の売上貢献度（円と構成比％）**と、そのグラフを作り、何がどれほど売上に貢献したのかを見","metadata":{}},{"cell_type":"code","source":"# 媒体別の貢献度の合計\ncontribution_sum = adj_contribution.sum(axis=0)\n#集計結果\nprint('売上貢献度（円）:\\n', \n      contribution_sum, \n      sep=''\n     )\nprint()\nprint('売上貢献度（構成比）:\\n', \n      contribution_sum/contribution_sum.sum(), \n      sep=''\n     )\n#グラフ化\ncontribution_sum.plot.pie(fontsize=24)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **費用対効果**を見てみます。今回は**媒体別にROIを計算**します。\n\n- 先ず、**媒体別のコスト**を集計","metadata":{}},{"cell_type":"code","source":"# 各媒体のコストの合計\ncost_sum = X.sum(axis=0)\ncost_sum #確認","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 先程求めた売上貢献度を使い、**媒体別のROIを計算しグラフ化**","metadata":{}},{"cell_type":"code","source":"# 各媒体のROIの計算\nROI = (contribution_sum.drop('Base', axis=0) - cost_sum)/cost_sum\n#確認\nprint('ROI:\\n', ROI, sep='')\n# グラフ化\nROI.plot.bar(fontsize=24)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **ROI**は、値が大きいほど良く、最低限プラスの値である必要があります。少なくとも0以上である必要があります。","metadata":{}},{"cell_type":"markdown","source":"***\n<a id=\"Saturation\"></a>\n<a id=\"Sat_Converter\"></a>\n## <p>**飽和モデル・変換器クラス**</p>\n\n- **指数型飽和モデル(exp_Saturation)**\n- **変換器クラス**","metadata":{}},{"cell_type":"code","source":"# 指数型飽和モデル（exp_Saturation）\ndef exp_Saturation(X,a):\n    '''\n    Hyperparameter : a\n    '''\n    return 1 - np.exp(-a*X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 指数型飽和モデル（exp_Saturation）変換器\nclass pipe_exp_Saturation(BaseEstimator, TransformerMixin):\n    \n    # 初期化\n    def __init__(self,a=1.0):\n        self.a = a\n    \n    # 学習\n    def fit(self, X, y=None):\n        return self\n    \n    # 処理（入力→出力）\n    def transform(self, X):\n        X_ = exp_Saturation(X,\n                            self.a\n                           ).reshape(-1,1)\n        return X_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **ロジスティック型飽和モデル(logit_Saturatrion)**\n- **変換器クラス**","metadata":{}},{"cell_type":"code","source":"# ロジスティック型飽和モデル（logit_Saturation）\ndef logit_Saturation(X,K,b,c,m):\n    '''\n    Hyperparameters : k, b, c, m\n    data : X\n    '''\n    return K/(1+b*np.exp(-c*(X-m)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ロジスティック型飽和モデル（logit_Saturation）変換器\nclass pipe_logit_Saturation(BaseEstimator, TransformerMixin):\n    \n    # 初期化\n    def __init__(self,K=1.0,m=100.0,b=1.0, c=0.1):\n        self.K = K\n        self.m = m\n        self.b = b\n        self.c = c\n    \n    # 学習\n    def fit(self, X, y=None):\n        return self\n    \n    # 処理（入力→出力）\n    def transform(self, X):\n        X_ = logit_Saturation(X,\n                              self.K, \n                              self.b, \n                              self.c, \n                              self.m\n                             ).reshape(-1,1)\n        return X_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **ゴンペルツ型飽和モデル(gom_Saturation)**\n- **変換器**","metadata":{}},{"cell_type":"code","source":"# ゴンペルツ型飽和モデル（gom_Saturation）\ndef gom_Saturation(X,K,b,c,m):\n    '''\n    Hyperparameters : k, b, c, m\n    data : X\n    '''\n    return K*(b**np.exp(-c*(X-m)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ゴンペルツ型飽和モデル（gom_Saturation）\nclass pipe_gom_Saturation(BaseEstimator, TransformerMixin):\n    \n    # 初期化\n    def __init__(self,K=1.0,m=100.0,b=1.0,c=0.1):\n        self.K = K\n        self.m = m\n        self.b = b\n        self.c = c\n    \n    # 学習\n    def fit(self, X, y=None):\n        return self\n    \n    # 処理（入力→出力）\n    def transform(self, X):\n        X_ = gom_Saturation(X,\n                            self.K, \n                            self.b, \n                            self.c, \n                            self.m\n                           ).reshape(-1,1)\n        return X_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n<a id=\"Converter\"></a>\n<a id=\"lag_Converter\"></a>\n## <p>**ラグ効果モデル・変換器**</p>\n- **定率減少型キャリーオーバー効果モデル　※ピークが広告などの投入時（simple_Carryover）**\n- **変換器**","metadata":{}},{"cell_type":"code","source":"# 定率減少型キャリーオーバー効果モデル　※ピークが広告などの投入時（simple_Carryover）\ndef simple_Carryover(X: np.ndarray, rate, length):\n    \n    filter = (\n        rate ** np.arange(length + 1)\n    ).reshape(-1, 1) \n    \n    convolution = convolve2d(X, filter)\n    \n    if length > 0 : convolution = convolution[: -length]\n        \n    return convolution[:,0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 定率減少型キャリーオーバー効果モデル　※ピークが広告など投入時（simple_Carryover）\nclass pipe_simple_Carryover(BaseEstimator, TransformerMixin):\n    # 初期化\n    def __init__(self,length=4,rate=0.5):\n        self.length = length\n        self.rate = rate\n        \n    # 学習        \n    def fit(self, X, y=None):\n        return self\n    # 処理（入力→出力）\n    def transform(self, X):\n        X_ = simple_Carryover(X, \n                              self.rate, \n                              self.length\n                             )\n        return X_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **ピーク可変型キャリーオーバー効果モデル（peak_Carryover）**\n- **変換器**","metadata":{}},{"cell_type":"code","source":"# ピーク可変型キャリーオーバー効果モデル（peak_Carryover）\ndef peak_Carryover(X: np.ndarray, length, peak, rate):\n    X = np.append(np.zeros(length-1), X)\n    \n    Ws = np.zeros(length)\n    \n    for l in range(length):\n        W = rate**((l-peak)**2)\n        Ws[length-1-l] = W\n    \n    carryover_X = []\n    \n    for i in range(length-1, len(X)):\n        X_array = X[i-length+1:i+1]\n        Xi = sum(X_array * Ws)/sum(Ws)\n        carryover_X.append(Xi)\n        \n    return np.array(carryover_X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pipeline用変換器（キャリーオーバー効果モデル）\nclass pipe_peak_Carryover(BaseEstimator, TransformerMixin):\n    # 初期化\n    def __init__(self,length=4,peak=1,rate=0.5):\n        self.length = length\n        self.peak = peak\n        self.rate = rate\n        \n    # 学習        \n    def fit(self, X, y=None):\n        return self\n    # 処理（入力→出力）\n    def transform(self, X):\n        X_ = peak_Carryover(X, \n                            self.length, \n                            self.peak, \n                            self.rate\n                           ) \n        return X_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **Optuna**","metadata":{}},{"cell_type":"code","source":"# 目的関数の設定\ndef objective(trial):\n    \n    #TVCM\n    \n    ##TVCM Adstock func\n    \n    TVCM_Saturation_func = trial.suggest_categorical(\n        \"TVCM_Saturation_func\",\n        [\"exp\", \"logit\",\"gom\"]\n    )\n    \n    TVCM_Carryover_func = trial.suggest_categorical(\n        \"TVCM_Carryover_func\",\n        [\"simple\", \"peak\"]\n    )\n    \n    ##TVCM_Saturation\n    \n    if TVCM_Saturation_func == 'exp':\n        \n        TVCM_a = trial.suggest_float(\n            \"TVCM_a\", \n            0, 0.01\n        )\n        \n        TVCM_Saturation = pipe_exp_Saturation(a=TVCM_a)\n        \n    elif TVCM_Saturation_func == 'logit':\n        \n        TVCM_K = trial.suggest_float(\n            \"TVCM_K\", \n            np.min(X.TVCM), np.max(X.TVCM)*2\n        )\n        TVCM_m = trial.suggest_float(\n            \"TVCM_m\",\n            np.min(X.TVCM), np.max(X.TVCM)\n        )\n        TVCM_b = trial.suggest_float(\n            \"TVCM_b\",\n            0, 10\n        )\n        TVCM_c = trial.suggest_float(\n            \"TVCM_c\",\n            0, 1\n        )\n        \n        TVCM_Saturation = pipe_logit_Saturation(\n            K=TVCM_K,\n            m=TVCM_m,\n            b=TVCM_b,\n            c=TVCM_c\n        )\n        \n    else:\n        \n        TVCM_K = trial.suggest_float(\n            \"TVCM_K\", \n            np.min(X.TVCM), \n            np.max(X.TVCM)*2\n        )\n        TVCM_m = trial.suggest_float(\n            \"TVCM_m\", \n            np.min(X.TVCM), \n            np.max(X.TVCM)\n        )\n        TVCM_b = trial.suggest_float(\n            \"TVCM_b\", \n            0, 1\n        )\n        TVCM_c = trial.suggest_float(\n            \"TVCM_c\", \n            0, 1\n        )     \n        \n        TVCM_Saturation = pipe_gom_Saturation(\n            K=TVCM_K,\n            m=TVCM_m,\n            b=TVCM_b,\n            c=TVCM_c\n        )\n        \n    ##TVCM Carryover\n    \n    if TVCM_Carryover_func == 'simple':\n        \n        TVCM_rate = trial.suggest_float(\n            \"TVCM_rate\", \n            0,1\n        )\n        TVCM_length = trial.suggest_int(\n            \"TVCM_length\", \n            0,6\n        )\n        \n        TVCM_Carryover = pipe_simple_Carryover(\n            length=TVCM_length,\n            rate=TVCM_rate\n        )\n        \n    else:\n        \n        TVCM_rate = trial.suggest_float(\n            \"TVCM_rate\", \n            0, 1\n        )\n        TVCM_length = trial.suggest_int(\n            \"TVCM_length\",\n            1,7\n        )\n        TVCM_peak = trial.suggest_int(\n            \"TVCM_peak\",\n            0,2\n        )\n        \n        TVCM_Carryover = pipe_peak_Carryover(\n            length=TVCM_length, \n            rate=TVCM_rate,\n            peak=TVCM_peak\n        )   \n    #Newspaper\n    \n    ##Newspaper Adstock func\n    \n    Newspaper_Saturation_func = trial.suggest_categorical(\n        \"Newspaper_Saturation_func\",\n        [\"exp\", \"logit\",\"gom\"]\n    )\n    \n    Newspaper_Carryover_func = trial.suggest_categorical(\n        \"Newspaper_Carryover_func\",\n        [\"simple\", \"peak\"]\n    )\n    \n    ##Newspaper_Saturation\n    \n    if Newspaper_Saturation_func == 'exp':\n        \n        Newspaper_a = trial.suggest_float(\n            \"Newspaper_a\", \n            0, 0.01\n        )\n        \n        Newspaper_Saturation = pipe_exp_Saturation(a=Newspaper_a)\n        \n    elif Newspaper_Saturation_func == 'logit':\n        \n        Newspaper_K = trial.suggest_float(\n            \"Newspaper_K\",\n            np.min(X.Newspaper), np.max(X.Newspaper)*2\n        )\n        Newspaper_m = trial.suggest_float(\n            \"Newspaper_m\", \n            np.min(X.Newspaper), np.max(X.Newspaper)\n        )\n        Newspaper_b = trial.suggest_float(\n            \"Newspaper_b\", \n            0, 10\n        )\n        Newspaper_c = trial.suggest_float(\n            \"Newspaper_c\", \n            0, 1\n        )\n        \n        Newspaper_Saturation = pipe_logit_Saturation(\n            K=Newspaper_K,\n            m=Newspaper_m,\n            b=Newspaper_b,\n            c=Newspaper_c\n        )\n        \n    else:\n        \n        Newspaper_K = trial.suggest_float(\n            \"Newspaper_K\", \n            np.min(X.Newspaper), np.max(X.Newspaper)*2\n        )\n        Newspaper_m = trial.suggest_float(\n            \"Newspaper_m\", \n            np.min(X.Newspaper), np.max(X.Newspaper)\n        )\n        Newspaper_b = trial.suggest_float(\n            \"Newspaper_b\", \n            0, 1\n        )\n        Newspaper_c = trial.suggest_float(\n            \"Newspaper_c\", \n            0, 1\n        )     \n        \n        Newspaper_Saturation = pipe_gom_Saturation(\n            K=Newspaper_K,\n            m=Newspaper_m,\n            b=Newspaper_b,\n            c=Newspaper_c\n        )\n        \n    ##Newspaper Carryover\n    \n    if Newspaper_Carryover_func == 'simple':\n        \n        Newspaper_rate = trial.suggest_float(\n            \"Newspaper_rate\", \n            0,1\n        )\n        Newspaper_length = trial.suggest_int(\n            \"Newspaper_length\", \n            0,6\n        )\n        \n        Newspaper_Carryover = pipe_simple_Carryover(\n            length=Newspaper_length,\n            rate=Newspaper_rate\n        )\n        \n    else:\n        \n        Newspaper_rate = trial.suggest_float(\n            \"Newspaper_rate\", \n            0, 1\n        )\n        Newspaper_length = trial.suggest_int(\n            \"Newspaper_length\",\n            1,7\n        )\n        Newspaper_peak = trial.suggest_int(\n            \"Newspaper_peak\",\n            0,2\n        )\n        \n        Newspaper_Carryover = pipe_peak_Carryover(\n            length=Newspaper_length,\n            rate=Newspaper_rate,\n            peak=Newspaper_peak\n        )\n            \n    #Web\n    \n    ##Web Adstock func\n    \n    Web_Saturation_func = trial.suggest_categorical(\n        \"Web_Saturation_func\",\n        [\"exp\", \"logit\",\"gom\"]\n    )\n    \n    Web_Carryover_func = trial.suggest_categorical(\n        \"Web_Carryover_func\",\n        [\"simple\", \"peak\"]\n    )\n    \n    ##Web_Saturation\n    \n    if Web_Saturation_func == 'exp':\n        \n        Web_a = trial.suggest_float(\n            \"Web_a\", \n            0, 0.01\n        )\n        \n        Web_Saturation = pipe_exp_Saturation(a=Web_a)\n        \n    elif Web_Saturation_func == 'logit':\n        \n        Web_K = trial.suggest_float(\n            \"Web_K\", \n            np.min(X.Web), np.max(X.Web)*2\n        )\n        Web_m = trial.suggest_float(\n            \"Web_m\", \n            np.min(X.Web), np.max(X.Web)\n        )\n        Web_b = trial.suggest_float(\n            \"Web_b\", \n            0, 10\n        )\n        Web_c = trial.suggest_float(\n            \"Web_c\", \n            0, 1\n        )\n        \n        Web_Saturation = pipe_logit_Saturation(\n            K=Web_K,\n            m=Web_m,\n            b=Web_b,\n            c=Web_c\n        )\n        \n    else:\n        \n        Web_K = trial.suggest_float(\n            \"Web_K\", \n            np.min(X.Web), np.max(X.Web)*2\n        )\n        Web_m = trial.suggest_float(\n            \"Web_m\", \n            np.min(X.Web), np.max(X.Web)\n        )\n        Web_b = trial.suggest_float(\n            \"Web_b\", \n            0, 1\n        )\n        Web_c = trial.suggest_float(\n            \"Web_c\", \n            0, 1\n        )     \n        \n        Web_Saturation = pipe_gom_Saturation(\n            K=Web_K,\n            m=Web_m,\n            b=Web_b,\n            c=Web_c\n        )\n        \n    ##Web Carryover\n    \n    if Web_Carryover_func == 'simple':\n        \n        Web_rate = trial.suggest_float(\n            \"Web_rate\", \n            0,1\n        )\n        Web_length = trial.suggest_int(\n            \"Web_length\", \n            0,6\n        )\n        \n        Web_Carryover = pipe_simple_Carryover(\n            length=Web_length,\n            rate=Web_rate\n        )\n        \n    else:\n        \n        Web_rate = trial.suggest_float(\n            \"Web_rate\", \n            0, 1\n        )\n        Web_length = trial.suggest_int(\n            \"Web_length\",\n            1,7\n        )\n        Web_peak = trial.suggest_int(\n            \"Web_peak\",\n            0,2\n        )\n        \n        Web_Carryover = pipe_peak_Carryover(\n            length=Web_length,\n            rate=Web_rate,\n            peak=Web_peak\n        )   \n    \n    # パイプライン化\n    \n    ## 変換器（Adstock）\n    adstock = ColumnTransformer(\n        [\n         ('TVCM_pipe', Pipeline([\n             ('TVCM_carryover', TVCM_Carryover),\n             ('TVCM_saturation', TVCM_Saturation)\n         ]), ['TVCM']),\n         ('Newspaper_pipe', Pipeline([\n             ('Newspaper_carryover', Newspaper_Carryover),\n             ('Newspaper_saturation', Newspaper_Saturation)\n         ]), ['Newspaper']),\n         ('Web_pipe', Pipeline([\n             ('Web_carryover', Web_Carryover),\n             ('Web_saturation', Web_Saturation)\n         ]), ['Web']),\n        ],\n        remainder='passthrough'\n    )\n    ## 説明変数の変換（adstock）→線形回帰モデル（regression）\n    MMM_pipe = Pipeline([\n        ('adstock', adstock),\n        ('regression', LinearRegression())\n    ])\n        \n    #CVによる評価\n    score = cross_val_score(\n        MMM_pipe,\n        X,\n        y,\n        cv=TimeSeriesSplit()\n    )\n    accuracy = score.mean()\n    return accuracy","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **目的関数に対し最適化を実行**することで、**最適な関数の組み合わせとそれぞれのハイパーパラメータを探索**","metadata":{}},{"cell_type":"code","source":"# 目的関数の最適化を実行する\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective,\n               n_trials=5000,\n               show_progress_bar=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 探索結果\nstudy.best_params","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **最適なハイパーパラメータでパイプラインを学習**\n- **求めた最適なハイパーパラメータでモデル構築し精度検証**\n- 具体的には、先ず**パイプラインの定義**をします。次に、そのパイプラインに最適なハイパーパラメータを設定します。そのパイプラインを使い、精度検証\n### **パイプライン構築**\n- パイプライン用の、**飽和モデル**と**キャリーオーバー効果の2つの変換器クラスを定義**","metadata":{}},{"cell_type":"code","source":"# Pipeline用変換器\n## 飽和モデル\nclass Saturation(BaseEstimator, TransformerMixin):\n    \n    # 初期化\n    def __init__(self,func='exp',a=1.0,K=1.0,m=100.0,b=1.0, c=0.1):\n        self.func = func\n        self.a = a\n        self.K = K\n        self.m = m\n        self.b = b\n        self.c = c\n    \n    # 学習\n    def fit(self, X, y=None):\n        return self\n    \n    # 処理（入力→出力）\n    def transform(self, X):\n        if self.func == 'exp':\n            X_ = exp_Saturation(X,\n                                self.a\n                               ).reshape(-1,1)\n        elif self.func == \"logit\":\n            X_ = logit_Saturation(X,\n                                  self.K, \n                                  self.b,\n                                  self.c, \n                                  self.m\n                                 ).reshape(-1,1)\n        else:\n            X_ = gom_Saturation(X,\n                                self.K, \n                                self.b, \n                                self.c, \n                                self.m\n                               ).reshape(-1,1)\n        return X_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## ラグ効果モデル\nclass Carryover(BaseEstimator, TransformerMixin):\n    # 初期化\n    def __init__(self,func='simple',length=4, peak=1, rate=0.5):\n        self.func = func\n        self.length = length\n        self.peak = peak\n        self.rate = rate\n        \n    # 学習        \n    def fit(self, X, y=None):\n        return self\n    # 処理（入力→出力）\n    def transform(self, X):\n        if self.func == 'peak':\n            X_ = peak_Carryover(X, \n                                self.length, \n                                self.peak, \n                                self.rate)  \n        else:\n            X_ = simple_Carryover(X, \n                                  self.rate, \n                                  self.length)\n            \n        return X_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **2つの変換器**で**アドストック（Ad Stock）**を表現します。これらの**変換器と学習器（線形回帰モデル）をつなげたパイプラインを構築**","metadata":{}},{"cell_type":"code","source":"# Pipelineの設定\n## 説明変数の変換部分（adstock）の定義\nadstock = ColumnTransformer(\n    [\n     ('TVCM_pipe', Pipeline([\n                           ('carryover', Carryover()),\n                           ('saturation', Saturation())\n     ]), ['TVCM']),\n     ('Newspaper_pipe', Pipeline([\n                           ('carryover', Carryover()),\n                           ('saturation', Saturation())\n     ]), ['Newspaper']),\n     ('Web_pipe', Pipeline([\n                           ('carryover', Carryover()),\n                           ('saturation', Saturation())\n     ]), ['Web']),\n    ],\n    remainder='passthrough'\n)\n\n## 説明変数の変換（adstock）→線形回帰モデル（regression）\nMMM_pipe = Pipeline([\n    ('adstock', adstock),\n    ('regression', LinearRegression())\n])\n\n## パイプラインの確認\nset_config(display='diagram')   \nMMM_pipe","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **先程求めた最適なハイパーパラメータを設定**","metadata":{}},{"cell_type":"code","source":"# パイプラインのハイパーパラメータの設定\nbest_params={\n 'adstock__TVCM_pipe__carryover__func': \n    study.best_params.get('TVCM_Carryover_func'),\n 'adstock__TVCM_pipe__carryover__length': \n    study.best_params.get('TVCM_length'),\n 'adstock__TVCM_pipe__carryover__peak': \n    study.best_params.get('TVCM_peak'),\n 'adstock__TVCM_pipe__carryover__rate': \n    study.best_params.get('TVCM_rate'),\n 'adstock__TVCM_pipe__saturation__func': \n    study.best_params.get('TVCM_Saturation_func'),\n 'adstock__TVCM_pipe__saturation__a': \n    study.best_params.get('TVCM_a'),\n 'adstock__TVCM_pipe__saturation__K': \n    study.best_params.get('TVCM_K'),\n 'adstock__TVCM_pipe__saturation__m': \n    study.best_params.get('TVCM_m'),\n 'adstock__TVCM_pipe__saturation__b': \n    study.best_params.get('TVCM_b'),\n 'adstock__TVCM_pipe__saturation__c': \n    study.best_params.get('TVCM_c'),\n 'adstock__Newspaper_pipe__carryover__func': \n    study.best_params.get('Newspaper_Carryover_func'),\n 'adstock__Newspaper_pipe__carryover__length': \n    study.best_params.get('Newspaper_length'),\n 'adstock__Newspaper_pipe__carryover__peak': \n    study.best_params.get('Newspaper_peak'),\n 'adstock__Newspaper_pipe__carryover__rate': \n    study.best_params.get('Newspaper_rate'),\n 'adstock__Newspaper_pipe__saturation__func': \n    study.best_params.get('Newspaper_Saturation_func'),\n 'adstock__Newspaper_pipe__saturation__a': \n    study.best_params.get('Newspaper_a'),\n 'adstock__Newspaper_pipe__saturation__K': \n    study.best_params.get('Newspaper_K'),\n 'adstock__Newspaper_pipe__saturation__m': \n    study.best_params.get('Newspaper_m'),\n 'adstock__Newspaper_pipe__saturation__b': \n    study.best_params.get('Newspaper_b'),\n 'adstock__Newspaper_pipe__saturation__c': \n    study.best_params.get('Newspaper_c'),\n 'adstock__Web_pipe__carryover__func':\n    study.best_params.get('Web_Carryover_func'),\n 'adstock__Web_pipe__carryover__length': \n    study.best_params.get('Web_length'),\n 'adstock__Web_pipe__carryover__peak': \n    study.best_params.get('Web_peak'),\n 'adstock__Web_pipe__carryover__rate': \n    study.best_params.get('Web_rate'),\n 'adstock__Web_pipe__saturation__func': \n    study.best_params.get('Web_Saturation_func'),\n 'adstock__Web_pipe__saturation__a': \n    study.best_params.get('Web_a'),\n 'adstock__Web_pipe__saturation__K': \n    study.best_params.get('Web_K'),\n 'adstock__Web_pipe__saturation__m': \n    study.best_params.get('Web_m'),\n 'adstock__Web_pipe__saturation__b': \n    study.best_params.get('Web_b'),\n 'adstock__Web_pipe__saturation__c': \n    study.best_params.get('Web_c'),\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **精度検証**","metadata":{}},{"cell_type":"code","source":"# パイプラインのインスタンス\nMMM_pipe_best = MMM_pipe.set_params(**best_params)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# クロスバリデーションで精度検証（R2）\nnp.mean(cross_val_score(MMM_pipe_best, \n                        X, y, \n                        cv=TimeSeriesSplit()\n                       )\n       )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 全データで精度検証（R2）\nMMM_pipe_best.fit(X, y)\nMMM_pipe_best.score(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 線形回帰モデルなのか（切片と回帰係数）","metadata":{}},{"cell_type":"code","source":"# 線形回帰モデルの切片と回帰係数\nintercept = MMM_pipe_best.named_steps['regression'].intercept_ #切片\ncoef = MMM_pipe_best.named_steps['regression'].coef_ #回帰係数\n# 回帰係数をデータフレーム化\nweights = pd.Series(\n    coef,\n    index=X.columns\n)\n# 結果出力（切片と係数）\nprint('Intercept:\\n', intercept, sep='')\nprint()\nprint('Coefficients:\\n',weights, sep='')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **売上貢献度の算出**\n- **パイプラインの変換器（adstock）を抽出**","metadata":{}},{"cell_type":"code","source":"# Piplineの変換器（adstock）を抽出\nadstock = MMM_pipe_best.named_steps['adstock']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **説明変数を変換し、学習データのインプットデータを作る**","metadata":{}},{"cell_type":"code","source":"# 説明変数Xの変換\nX_trans = pd.DataFrame(adstock.transform(X),\n                       index=X.\n                       index,columns=X.columns)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **先程求めた線形回帰式を使い、売上貢献度（補正前）を計算**","metadata":{}},{"cell_type":"code","source":"# 貢献度（補正前）\nunadj_contribution = X_trans.mul(weights) #Xと係数を乗算\nunadj_contribution = unadj_contribution.assign(Base=intercept) #切片の追加\nunadj_contribution.head() #確認","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 週ごとに各媒体の売上貢献度を合計すると、**売上の予測値**","metadata":{}},{"cell_type":"code","source":"# 貢献度の合計（yの予測値）\ny_pred = unadj_contribution.sum(axis=1)\ny_pred.head() #確認","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.head() #確認","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **予測値と実測値が乖離**していることが分かります。この乖離をなくすために、**補正係数（correction factor）**を計算し、**売上貢献度を補正**","metadata":{}},{"cell_type":"code","source":"# 補正係数\ncorrection_factor = y.div(y_pred, axis=0)\ncorrection_factor.head() #確認","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- この**補正係数**を使い、**売上貢献度を補正**","metadata":{}},{"cell_type":"code","source":"# 貢献度（補正後）\nadj_contribution = (unadj_contribution\n                    .mul(correction_factor, axis=0)\n                   ) \n# 順番の変更\nadj_contribution = adj_contribution[['Base', 'Web', 'Newspaper', 'TVCM']]\n#確認\nadj_contribution.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **週×媒体別の売上貢献度**が求められたので、**積み上げグラフ**を作成","metadata":{}},{"cell_type":"code","source":"# グラフ化\nax = (adj_contribution\n      .plot.area(\n          figsize=(16, 10),\n          linewidth=0,\n          ylabel='Sales',\n          xlabel='Date')\n     )\nhandles, labels = ax.get_legend_handles_labels()\nax.legend(handles[::-1], labels[::-1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **媒体別に全ての週の売上貢献度を合計**し、**媒体別の売上貢献度（円と構成比％）**と、そのグラフを作り、**何がどれほど売上に貢献したのか**","metadata":{}},{"cell_type":"code","source":"# 媒体別の貢献度の合計\ncontribution_sum = adj_contribution.sum(axis=0)\n#集計結果\nprint('売上貢献度（円）:\\n', \n      contribution_sum, \n      sep=''\n     )\nprint()\nprint('売上貢献度（構成比）:\\n', \n      contribution_sum/contribution_sum.sum(), \n      sep=''\n     )\n#グラフ化\ncontribution_sum.plot.pie(fontsize=24)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **費用対効果**を見てみます。今回は媒**体別にROIを計算**します。\n- 先ず、**媒体別のコスト**を集計","metadata":{}},{"cell_type":"code","source":"# 各媒体のコストの合計\ncost_sum = X.sum(axis=0)\ncost_sum #確認","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 先程求めた売上貢献度を使い、**媒体別のROIを計算しグラフ化**","metadata":{}},{"cell_type":"code","source":"# 各媒体のROIの計算\nROI = (contribution_sum.drop('Base', axis=0) - cost_sum)/cost_sum\n#確認\nprint('ROI:\\n', ROI, sep='')\n# グラフ化\nROI.plot.bar(fontsize=24)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **ROI**は、値が大きいほど良く、少なくとも0以上である必要があります。\n- TVCMは0以上なのはTVCMとWebです。Webが非常にいいということが分かります。一方、Newspaperは0未満なので、少なくとも止めたほうが良","metadata":{}},{"cell_type":"markdown","source":"***\n<a id=\"RLE\"></a>\n# <p>**Ridge,Lasso,ElasticNet**</p>\n- **広告・販促は似たような時期に集中し実施**されるので、変数間で相関が発生する。**この問題の解決として正則化項を持つ線形回帰を行う**\n- モデルの説明力や予測精度は若干悪化するが、有効な手段\n    - **線形回帰**\n        - 通常の線形回帰モデルは、**最小二乗法**という方法で回帰式の**回帰係数を求める(定数含む)**\n            - $y_{i}=\\beta_{0}+/displaystyle\\sum_{j=1}^{p}\\beta_{j}x_{ij}$\n            - yが目的変数で、xが説明変数。pが説明変数の数で、nがデータ数(データセットの行数)\n                - 何かしら回帰係数(定数含む)を設定すると、何かしらの線形回帰式が出来上がる。何かしらの線形回帰式が出来上がれば、yの予測値を求めれる\n                - **予測値と実測値の差を二乗した値を最小化**するような**回帰係数(定数含む)**を求める方法が、**最小二乗法**\n                    - $\\hat{\\beta}=\\underset{\\beta}{\\operatorname{argmin}}\\lbrace \\displaystyle\\sum_{i=1}^{n}(\\beta_{0}+\\displaystyle\\sum_{j=1}^{p}\\beta_{j}x_{ij}-y_{j})^{2} \\rbrace$\n                - **最小二乗法にある制約(正則化項)**を付け加えた、**制約(正則化項)付き最小二乗法**という方法で回帰式の回帰係数(定数含む)を求めるのが、**正則化付き線形回帰モデル**\n                    - 通常線形回帰モデルと比べ、求めた回帰係数(定数含む)が0の方向に縮小(絶対値が小さくなる)\n                    - この**制約(正則化項)付き最小二乗法**という方法で回帰式の回帰係数(定数含む)を求めるのが、**正則化項付き線形回帰モデル**\n                    - この**制約(正則化項)**により、説明変数同士の相関が高いために起こる不具合や過学習などの影響を緩和する。\n                - [**Ridge回帰**](#ridge)\n                    - **線形回帰モデルの回帰係数の二乗和を正則化項として加えた推定法**\n                    - **ハイパーパラメータ**として、**正則化項の重み（正則化パラメータ）を設定**する必要\n                        - $\\hat{\\beta}_{ridge}=\\underset{\\beta}{\\operatorname{argmin}}\\lbrace \\displaystyle\\sum_{i=1}^{n}(\\beta_{0}+\\displaystyle\\sum_{j=1}^{p}\\beta_{j}x_{ij}-y_{j})^{2}+\\lambda \\displaystyle\\sum_{j=1}^{p}\\beta_{j}^{2} \\rbrace$\n                - **Lasso回帰**\n                    - **Ridge回帰と異なり**、**回帰係数を0にするため変数選択を自動で実施**\n                    - **線形回帰モデルの回帰係数の絶対値の和を正則化項として加えた推定法**\n                    - **ハイパーパラメータ**として、**正則化項の重み（正則化パラメータ）を設定**する必要\n                        - $\\hat{\\beta}_{Lasso}=\\underset{\\beta}{\\operatorname{argmin}}\\lbrace \\displaystyle\\sum_{i=1}^{n}(\\beta_{0}+\\displaystyle\\sum_{j=1}^{p}\\beta_{j}x_{ij}-y_{j})^{2}+\\lambda \\displaystyle\\sum_{j=1}^{p}|\\beta_{j}| \\rbrace$\n                - **ElasticNet回帰**\n                    - **ハイパーパラメータ**として、その**割合を設定**\n                    - **ハイパーパラメータ**として、**正則化項の重み（正則化パラメータ）を設定**\n                        - $\\hat{\\beta}_{elasticnet}=\\underset{\\beta}{\\operatorname{argmin}}\\lbrace \\displaystyle\\sum_{i=1}^{n}(\\beta_{0}+\\displaystyle\\sum_{j=1}^{p}\\beta_{j}x_{ij}-y_{j})^{2}+\\lambda \\displaystyle\\sum_{j=1}^{p}(\\alpha|\\beta_{j}|+(1+\\alpha)\\beta_{j}^{2}) \\rbrace$\n                        \n    - **方法**\n        - **AdStockを考慮しないRidge回帰**\n            - AdStockを考慮していないのでパイプラインは構築しない。\n        - **シンプルなAdStock考慮**\n        - **様々なAdStock考慮**\n            - [**最適な組み合わせ**](#Add_all)\n                - **飽和モデル** : **指数型飽和モデル・ロジスティック型飽和モデル・ゴンペルツ型飽和モデル**\n                - **ラグモデル** : **定率減少型ラグ効果モデル・ピーク可変型ラグ効果モデル**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Ridge","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Optunaハイパーパラメータ探索\n\n# Ridge回帰のインスタンス生成\nMMM=Ridge()\n\n# 探索するハイパーパラメータ範囲の設定\nparams = {\n 'alpha': UniformDistribution(0.01, 1e10),\n}\n\n# ハイパーパラメータ探索の設定\noptuna_search = OptunaSearchCV(\n    estimator=MMM,\n    param_distributions=params,\n    n_trials=1000,\n    cv=TimeSeriesSplit(),\n    random_state=123,\n)\n\n# 探索実施\noptuna_search.fit(X, y)\n\n# 探索結果\noptuna_search.best_params_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **最適ハイパーパラメータで学習**","metadata":{}},{"cell_type":"code","source":"# 最適ハイパーパラメータで学習\n\n# パイプラインのインスタンス\nMMM_best = MMM.set_params(**optuna_search.best_params_)\n\n# 全データで学習\nMMM_best.fit(X, y)\n\n# R2（決定係数）\nMMM_best.score(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **予測式の確認**","metadata":{}},{"cell_type":"code","source":"# 予測式の確認\n\n# 線形回帰モデルの切片と回帰係数\nintercept = MMM_best.intercept_ #切片\ncoef = MMM_best.coef_           #回帰係数\nalpha = MMM_best.alpha          #正則化パラメータ\n\n# 回帰係数をSeries（シリーズ）化\nweights = pd.Series(\n    coef,\n    index=X.columns\n)\n\n# 結果出力（切片と係数）\nprint('Intercept:\\n', intercept, sep='')\nprint()\nprint('Coefficients:\\n',weights, sep='')\nprint()\nprint('alpha:\\n', alpha, sep='')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **予測の実施**","metadata":{}},{"cell_type":"code","source":"# 予測の実施\n\n# 目的変数y（売上）の予測\npred = pd.DataFrame(MMM_best.predict(X),\n                    index=X.index,\n                    columns=['y'])\n# 各媒体による売上の予測\n## 値がすべて0の説明変数\nX_ = X.copy()\nX_.iloc[:,:]=0\n## Base\npred['Base'] = MMM_best.predict(X_)\n## 媒体\nfor i in range(len(X.columns)):\n    X_.iloc[:,:]=0\n    X_.iloc[:,i]=X.iloc[:,i]\n    pred[X.columns[i]] = MMM_best.predict(X_) - pred['Base']\n    \nprint(pred) #確認","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **貢献度の算定**","metadata":{}},{"cell_type":"code","source":"# 予測値の補正\ncorrection_factor = y.div(pred['y'], axis=0)   #補正係数\npred_adj = pred.mul(correction_factor, axis=0) #補正後の予測値\n# 各媒体の貢献度だけ抽出\ncontribution = pred_adj[['Base', 'Web', 'Newspaper', 'TVCM']]\nprint(contribution.head()) #確認\n# グラフ化\nax = (contribution\n      .plot.area(\n          ylabel='Sales',\n          xlabel='Week')\n     )\nhandles, labels = ax.get_legend_handles_labels()\nax.legend(handles[::-1], labels[::-1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **貢献度の構成比の算出**","metadata":{}},{"cell_type":"code","source":"# 媒体別の貢献度の合計\ncontribution_sum = contribution.sum(axis=0)\n# 集計結果の出力\nprint('売上貢献度（円）:\\n', \n      contribution_sum, \n      sep=''\n     )\nprint()\nprint('売上貢献度（構成比）:\\n', \n      contribution_sum/contribution_sum.sum(), \n      sep=''\n     )\n# グラフ化\ncontribution_sum.plot.pie(fontsize=24)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **マーケティングROIの算定**","metadata":{}},{"cell_type":"code","source":"# マーケティングROIの算定\n\n# 各媒体のコストの合計\ncost_sum = X.sum(axis=0)\n\n# 各媒体のROIの計算\nROI = (contribution_sum.drop('Base', axis=0) - cost_sum)/cost_sum\nprint('ROI:\\n', ROI, sep='') #確認\n\n# グラフ化\nROI.plot.bar(fontsize=24)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n<a id=\"ridge\"></a>\n## <p>**Ridge + Optuna**</p>\n- **正則化ハイパーパラメータを探査**","metadata":{}},{"cell_type":"markdown","source":"- **飽和モデル + 変換器**","metadata":{}},{"cell_type":"code","source":"# 飽和モデル\ndef Saturation(X,a):\n    return 1 - np.exp(-a*X)\n\n## 飽和モデル：変換器\nclass ExponentialSaturation(BaseEstimator, TransformerMixin):\n    \n    # 初期化\n    def __init__(self, a=1.0):\n        self.a = a #ハイパーパラメータ\n    \n    # 学習\n    def fit(self, X, y=None):\n        return self\n    \n    # 処理（入力→出力）\n    def transform(self, X):\n        return Saturation(X,self.a)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **ラグモデル + 変換器**","metadata":{}},{"cell_type":"code","source":"# ラグ効果モデル\ndef Carryover(X: np.ndarray, rate, length):\n    filter = (\n        rate ** np.arange(length)\n    ).reshape(-1, 1) \n    convolution = convolve2d(X, filter)\n    if length > 1 : convolution = convolution[: -(length-1)]\n    return convolution\n\n## ラグモデル：変換器\nclass ExponentialCarryover(BaseEstimator, TransformerMixin):\n    # 初期化\n    def __init__(self, rate=0.5, length=1):\n        self.rate = rate #ハイパーパラメータ\n        self.length = length #ハイパーパラメータ\n        \n    # 学習        \n    def fit(self, X, y=None):\n        return self\n    \n    # 処理（入力→出力）\n    def transform(self, X: np.ndarray):\n        return Carryover(X, self.rate, self.length)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **Pipeline構築**","metadata":{}},{"cell_type":"code","source":"# Pipeline\n\n# 変換器（adstock）\nadstock = ColumnTransformer(\n    [\n     ('TVCM_pipe', Pipeline([\n                           ('carryover', ExponentialCarryover()),\n                           ('saturation', ExponentialSaturation())\n     ]), ['TVCM']),\n     ('Newspaper_pipe', Pipeline([\n                           ('carryover', ExponentialCarryover()),\n                           ('saturation', ExponentialSaturation())\n     ]), ['Newspaper']),\n     ('Web_pipe', Pipeline([\n                           ('carryover', ExponentialCarryover()),\n                           ('saturation', ExponentialSaturation())\n     ]), ['Web']),\n    ],\n    remainder='passthrough'\n)\n\n## 変換器（adstock）→学習器（regression）\nMMM_pipe = Pipeline([\n    ('adstock', adstock),\n    ('regression', Ridge())\n])\n\n## パイプラインの確認\nset_config(display='diagram')   \nMMM_pipe","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **Pipeline : ハイパーパラメータ探索**","metadata":{}},{"cell_type":"code","source":"# ハイパーパラメータ探索\n\n# 探索するハイパーパラメータ範囲の設定\nparams = {\n    \n ## Ridge\n 'regression__alpha':\n    UniformDistribution(0.01, 10000),\n    \n ## TVCM\n 'adstock__TVCM_pipe__carryover__rate':\n    UniformDistribution(0, 1),\n 'adstock__TVCM_pipe__carryover__length':\n    IntUniformDistribution(1, 6),\n 'adstock__TVCM_pipe__saturation__a':\n    UniformDistribution(0, 0.01),\n    \n ## Newspaper\n 'adstock__Newspaper_pipe__carryover__rate':\n    UniformDistribution(0, 1),\n 'adstock__Newspaper_pipe__carryover__length':\n    IntUniformDistribution(1, 6),\n 'adstock__Newspaper_pipe__saturation__a':\n    UniformDistribution(0, 0.01),\n    \n ## Web\n 'adstock__Web_pipe__carryover__rate':\n    UniformDistribution(0, 1),\n 'adstock__Web_pipe__carryover__length':\n    IntUniformDistribution(1, 6),\n 'adstock__Web_pipe__saturation__a':\n    UniformDistribution(0, 0.01),\n}\n\n# ハイパーパラメータ探索の設定\noptuna_search = OptunaSearchCV(\n    estimator=MMM_pipe,\n    param_distributions=params,\n    n_trials=2000,\n    cv=TimeSeriesSplit(),\n    random_state=0,\n)\n\n# 探索実施\noptuna_search.fit(X, y)\n\n# 探索結果\noptuna_search.best_params_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **モデルの構築と予測**\n    - **最適ハイパーパラメータで学習**","metadata":{}},{"cell_type":"code","source":"# 最適ハイパーパラメータで学習\n\n# パイプラインのインスタンス\nMMM_pipe_best = MMM_pipe.set_params(**optuna_search.best_params_)\n\n# 全データで学習\nMMM_pipe_best.fit(X, y)\n\n# R2（決定係数）\nMMM_pipe_best.score(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **予測式の確認**","metadata":{}},{"cell_type":"code","source":"# 予測式の確認\n\n# 線形回帰モデルの切片と回帰係数\nintercept = MMM_pipe_best.named_steps['regression'].intercept_ #切片\ncoef = MMM_pipe_best.named_steps['regression'].coef_ #回帰係数\nalpha = MMM_pipe_best.named_steps['regression'].alpha #正則化パラメータ\n\n# 回帰係数をSeries（シリーズ）化\nweights = pd.Series(\n    coef,\n    index=X.columns\n)\n\n# 結果出力（切片と係数）\nprint('Intercept:\\n', intercept, sep='')\nprint()\nprint('Coefficients:\\n',weights, sep='')\nprint()\nprint('alpha:\\n', alpha, sep='')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **予測の実施**","metadata":{}},{"cell_type":"code","source":"# 予測の実施\n\n# 目的変数y（売上）の予測\npred = pd.DataFrame(MMM_pipe_best.predict(X),\n                    index=X.index,\n                    columns=['y'])\n\n# 各媒体による売上の予測\n\n## 値がすべて0の説明変数\nX_ = X.copy()\nX_.iloc[:,:]=0\n\n## Base\npred['Base'] = MMM_pipe_best.predict(X_)\n\n## 媒体\nfor i in range(len(X.columns)):\n    X_.iloc[:,:]=0\n    X_.iloc[:,i]=X.iloc[:,i]\n    pred[X.columns[i]] = MMM_pipe_best.predict(X_) - pred['Base']\n    \nprint(pred) #確認","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **貢献度とマーケティングROIの算定**\n- **貢献度の算定**","metadata":{}},{"cell_type":"code","source":"# 貢献度の算定\n\n# 予測値の補正\ncorrection_factor = y.div(pred['y'], axis=0)   #補正係数\npred_adj = pred.mul(correction_factor, axis=0) #補正後の予測値\n\n# 各媒体の貢献度だけ抽出\ncontribution = pred_adj[['Base', 'Web', 'Newspaper', 'TVCM']]\nprint(contribution.head())\n\n# グラフ化\nax = (contribution\n      .plot.area(\n          ylabel='Sales',\n          xlabel='Week')\n     )\n\nhandles, labels = ax.get_legend_handles_labels()\nax.legend(handles[::-1], labels[::-1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **貢献度の構成比**","metadata":{}},{"cell_type":"code","source":"# 貢献度の構成比\n\n# 媒体別の貢献度の合計\ncontribution_sum = contribution.sum(axis=0)\n\n# 集計結果の出力\nprint('売上貢献度（円）:\\n', \n      contribution_sum, \n      sep=''\n     )\nprint()\nprint('売上貢献度（構成比）:\\n', \n      contribution_sum/contribution_sum.sum(), \n      sep=''\n     )\n\n# グラフ化\ncontribution_sum.plot.pie(fontsize=24)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **マーケティングROI**","metadata":{}},{"cell_type":"code","source":"# マーケティングROIの算定\n\n# 各媒体のコストの合計\ncost_sum = X.sum(axis=0)\n\n# 各媒体のROIの計算\nROI = (contribution_sum.drop('Base', axis=0) - cost_sum)/cost_sum\nprint('ROI:\\n', ROI, sep='') #確認\n\n# グラフ化\nROI.plot.bar(fontsize=24)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n<a id=\"Add_all\"></a>\n### <p>**最適な組み合わせ**</p>\n- **飽和モデル** : **指数型飽和モデル・ロジスティック型飽和モデル・ゴンペルツ型飽和モデル**\n- **ラグモデル** : **定率減少型ラグ効果モデル・ピーク可変型ラグ効果モデル**","metadata":{}},{"cell_type":"markdown","source":"- **飽和モデル**","metadata":{}},{"cell_type":"code","source":"# 飽和モデル\n\n# 指数型飽和モデル（exp_Saturation）\ndef exp_Saturation(X: np.ndarray,a):\n    return 1 - np.exp(-a*X)\n\n# ロジスティック型飽和モデル（logit_Saturation）\ndef logit_Saturation(X: np.ndarray,K,b,c,m):\n    return K/(1+b*np.exp(-c*(X-m)))\n\n# ゴンペルツ型飽和モデル（gom_Saturation）\ndef gom_Saturation(X: np.ndarray,K,b,c,m):\n    return K*(b**np.exp(-c*(X-m)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 変換器\n\n# 指数型飽和モデル（exp_Saturation）\nclass pipe_exp_Saturation(BaseEstimator, TransformerMixin):\n    \n    # 初期化\n    def __init__(self,a=1.0):\n        self.a = a\n    \n    # 学習\n    def fit(self, X, y=None):\n        return self\n    \n    # 処理（入力→出力）\n    def transform(self, X):\n        X_ = exp_Saturation(X,\n                            self.a\n                           ).reshape(-1,1)\n        return X_\n\n# ロジスティック型飽和モデル（logit_Saturation）\nclass pipe_logit_Saturation(BaseEstimator, TransformerMixin):\n    \n    # 初期化\n    def __init__(self,K=1.0,m=100.0,b=1.0, c=0.1):\n        self.K = K\n        self.m = m\n        self.b = b\n        self.c = c\n    \n    # 学習\n    def fit(self, X, y=None):\n        return self\n    \n    # 処理（入力→出力）\n    def transform(self, X):\n        X_ = logit_Saturation(X,\n                              self.K, \n                              self.b, \n                              self.c, \n                              self.m\n                             ).reshape(-1,1)\n        return X_\n\n# ゴンペルツ型飽和モデル（gom_Saturation）\nclass pipe_gom_Saturation(BaseEstimator, TransformerMixin):\n    \n    # 初期化\n    def __init__(self,K=1.0,m=100.0,b=1.0,c=0.1):\n        self.K = K\n        self.m = m\n        self.b = b\n        self.c = c\n    \n    # 学習\n    def fit(self, X, y=None):\n        return self\n    \n    # 処理（入力→出力）\n    def transform(self, X):\n        X_ = gom_Saturation(X,\n                            self.K, \n                            self.b, \n                            self.c, \n                            self.m\n                           ).reshape(-1,1)\n        return X_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **ラグ効果モデル**","metadata":{}},{"cell_type":"code","source":"# ラグ効果モデル\n\n# 定率減少型ラグ効果モデル（simple_Carryover）\ndef simple_Carryover(X: np.ndarray, rate, length):\n    \n    filter = (\n        rate ** np.arange(length)\n    ).reshape(-1, 1) \n    \n    convolution = convolve2d(X, filter)\n    \n    if length > 1 : convolution = convolution[: -(length-1)]\n        \n    return convolution\n\n# ピーク可変型ラグ効果モデル（peak_Carryover）\ndef peak_Carryover(X: np.ndarray, length, peak, rate):\n    X = np.append(np.zeros(length-1), X)\n    \n    Ws = np.zeros(length)\n    \n    for l in range(length):\n        W = rate**((l-peak)**2)\n        Ws[length-1-l] = W\n    \n    carryover_X = []\n    \n    for i in range(length-1, len(X)):\n        X_array = X[i-length+1:i+1]\n        Xi = sum(X_array * Ws)/sum(Ws)\n        carryover_X.append(Xi)\n        \n    return np.array(carryover_X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 変換器\n\n# 定率減少型ラグ効果モデル　※ピークが広告など投入時（simple_Carryover）\nclass pipe_simple_Carryover(BaseEstimator, TransformerMixin):\n    # 初期化\n    def __init__(self,length=4,rate=0.5):\n        self.length = length\n        self.rate = rate\n        \n    # 学習        \n    def fit(self, X, y=None):\n        return self\n    # 処理（入力→出力）\n    def transform(self, X):\n        X_ = simple_Carryover(X, \n                              self.rate, \n                              self.length\n                             )\n        return X_\n    \n# ピーク可変型ラグ効果モデル\nclass pipe_peak_Carryover(BaseEstimator, TransformerMixin):\n    # 初期化\n    def __init__(self,length=4,peak=1,rate=0.5):\n        self.length = length\n        self.peak = peak\n        self.rate = rate\n        \n    # 学習        \n    def fit(self, X, y=None):\n        return self\n    # 処理（入力→出力）\n    def transform(self, X):\n        X_ = peak_Carryover(X, \n                            self.length, \n                            self.peak, \n                            self.rate\n                           ) \n        return X_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **Optunaで利用する目的関数を定義**","metadata":{}},{"cell_type":"code","source":"# 目的関数の設定\ndef objective(trial):\n    \n    #Ridge\n    \n    alpha = trial.suggest_float(\n        \"alpha\",\n        0.01, 10000\n    )\n    \n    #TVCM\n    ##TVCM Adstock func\n    \n    TVCM_Saturation_func = trial.suggest_categorical(\n        \"TVCM_Saturation_func\",\n        [\"exp\", \"logit\",\"gom\"]\n    )\n    \n    TVCM_Carryover_func = trial.suggest_categorical(\n        \"TVCM_Carryover_func\",\n        [\"simple\", \"peak\"]\n    )\n    \n    ##TVCM_Saturation\n    \n    if TVCM_Saturation_func == 'exp':\n        \n        TVCM_a = trial.suggest_float(\n            \"TVCM_a\", \n            0, 0.01\n        )\n        \n        TVCM_Saturation = pipe_exp_Saturation(a=TVCM_a)\n        \n    elif TVCM_Saturation_func == 'logit':\n        \n        TVCM_K = trial.suggest_float(\n            \"TVCM_K\", \n            np.min(X.TVCM), np.max(X.TVCM)*2\n        )\n        TVCM_m = trial.suggest_float(\n            \"TVCM_m\",\n            np.min(X.TVCM), np.max(X.TVCM)\n        )\n        TVCM_b = trial.suggest_float(\n            \"TVCM_b\",\n            0, 10\n        )\n        TVCM_c = trial.suggest_float(\n            \"TVCM_c\",\n            0, 1\n        )\n        \n        TVCM_Saturation = pipe_logit_Saturation(\n            K=TVCM_K,\n            m=TVCM_m,\n            b=TVCM_b,\n            c=TVCM_c\n        )\n        \n    else:\n        \n        TVCM_K = trial.suggest_float(\n            \"TVCM_K\", \n            np.min(X.TVCM), \n            np.max(X.TVCM)*2\n        )\n        TVCM_m = trial.suggest_float(\n            \"TVCM_m\", \n            np.min(X.TVCM), \n            np.max(X.TVCM)\n        )\n        TVCM_b = trial.suggest_float(\n            \"TVCM_b\", \n            0, 1\n        )\n        TVCM_c = trial.suggest_float(\n            \"TVCM_c\", \n            0, 1\n        )     \n        \n        TVCM_Saturation = pipe_gom_Saturation(\n            K=TVCM_K,\n            m=TVCM_m,\n            b=TVCM_b,\n            c=TVCM_c\n        )\n        \n    ##TVCM Carryover\n    \n    if TVCM_Carryover_func == 'simple':\n        \n        TVCM_rate = trial.suggest_float(\n            \"TVCM_rate\", \n            0,1\n        )\n        TVCM_length = trial.suggest_int(\n            \"TVCM_length\", \n            1,6\n        )\n        \n        TVCM_Carryover = pipe_simple_Carryover(\n            length=TVCM_length,\n            rate=TVCM_rate\n        )\n        \n    else:\n        \n        TVCM_rate = trial.suggest_float(\n            \"TVCM_rate\", \n            0, 1\n        )\n        TVCM_length = trial.suggest_int(\n            \"TVCM_length\",\n            1,6\n        )\n        TVCM_peak = trial.suggest_int(\n            \"TVCM_peak\",\n            0,2\n        )\n        \n        TVCM_Carryover = pipe_peak_Carryover(\n            length=TVCM_length, \n            rate=TVCM_rate,\n            peak=TVCM_peak\n        )   \n        \n    #Newspaper\n    ##Newspaper Adstock func\n    \n    Newspaper_Saturation_func = trial.suggest_categorical(\n        \"Newspaper_Saturation_func\",\n        [\"exp\", \"logit\",\"gom\"]\n    )\n    \n    Newspaper_Carryover_func = trial.suggest_categorical(\n        \"Newspaper_Carryover_func\",\n        [\"simple\", \"peak\"]\n    )\n    \n    ##Newspaper_Saturation\n    \n    if Newspaper_Saturation_func == 'exp':\n        \n        Newspaper_a = trial.suggest_float(\n            \"Newspaper_a\", \n            0, 0.01\n        )\n        \n        Newspaper_Saturation = pipe_exp_Saturation(a=Newspaper_a)\n        \n    elif Newspaper_Saturation_func == 'logit':\n        \n        Newspaper_K = trial.suggest_float(\n            \"Newspaper_K\",\n            np.min(X.Newspaper), np.max(X.Newspaper)*2\n        )\n        Newspaper_m = trial.suggest_float(\n            \"Newspaper_m\", \n            np.min(X.Newspaper), np.max(X.Newspaper)\n        )\n        Newspaper_b = trial.suggest_float(\n            \"Newspaper_b\", \n            0, 10\n        )\n        Newspaper_c = trial.suggest_float(\n            \"Newspaper_c\", \n            0, 1\n        )\n        \n        Newspaper_Saturation = pipe_logit_Saturation(\n            K=Newspaper_K,\n            m=Newspaper_m,\n            b=Newspaper_b,\n            c=Newspaper_c\n        )\n        \n    else:\n        \n        Newspaper_K = trial.suggest_float(\n            \"Newspaper_K\", \n            np.min(X.Newspaper), np.max(X.Newspaper)*2\n        )\n        Newspaper_m = trial.suggest_float(\n            \"Newspaper_m\", \n            np.min(X.Newspaper), np.max(X.Newspaper)\n        )\n        Newspaper_b = trial.suggest_float(\n            \"Newspaper_b\", \n            0, 1\n        )\n        Newspaper_c = trial.suggest_float(\n            \"Newspaper_c\", \n            0, 1\n        )     \n        \n        Newspaper_Saturation = pipe_gom_Saturation(\n            K=Newspaper_K,\n            m=Newspaper_m,\n            b=Newspaper_b,\n            c=Newspaper_c\n        )\n        \n    ##Newspaper Carryover\n    \n    if Newspaper_Carryover_func == 'simple':\n        \n        Newspaper_rate = trial.suggest_float(\n            \"Newspaper_rate\", \n            0,1\n        )\n        Newspaper_length = trial.suggest_int(\n            \"Newspaper_length\", \n            1,6\n        )\n        \n        Newspaper_Carryover = pipe_simple_Carryover(\n            length=Newspaper_length,\n            rate=Newspaper_rate\n        )\n        \n    else:\n        \n        Newspaper_rate = trial.suggest_float(\n            \"Newspaper_rate\", \n            0, 1\n        )\n        Newspaper_length = trial.suggest_int(\n            \"Newspaper_length\",\n            1,6\n        )\n        Newspaper_peak = trial.suggest_int(\n            \"Newspaper_peak\",\n            0,2\n        )\n        \n        Newspaper_Carryover = pipe_peak_Carryover(\n            length=Newspaper_length,\n            rate=Newspaper_rate,\n            peak=Newspaper_peak\n        )\n            \n    #Web\n    ##Web Adstock func\n    \n    Web_Saturation_func = trial.suggest_categorical(\n        \"Web_Saturation_func\",\n        [\"exp\", \"logit\",\"gom\"]\n    )\n    \n    Web_Carryover_func = trial.suggest_categorical(\n        \"Web_Carryover_func\",\n        [\"simple\", \"peak\"]\n    )\n    \n    ##Web_Saturation\n    \n    if Web_Saturation_func == 'exp':\n        \n        Web_a = trial.suggest_float(\n            \"Web_a\", \n            0, 0.01\n        )\n        \n        Web_Saturation = pipe_exp_Saturation(a=Web_a)\n        \n    elif Web_Saturation_func == 'logit':\n        \n        Web_K = trial.suggest_float(\n            \"Web_K\", \n            np.min(X.Web), np.max(X.Web)*2\n        )\n        Web_m = trial.suggest_float(\n            \"Web_m\", \n            np.min(X.Web), np.max(X.Web)\n        )\n        Web_b = trial.suggest_float(\n            \"Web_b\", \n            0, 10\n        )\n        Web_c = trial.suggest_float(\n            \"Web_c\", \n            0, 1\n        )\n        \n        Web_Saturation = pipe_logit_Saturation(\n            K=Web_K,\n            m=Web_m,\n            b=Web_b,\n            c=Web_c\n        )\n        \n    else:\n        \n        Web_K = trial.suggest_float(\n            \"Web_K\", \n            np.min(X.Web), np.max(X.Web)*2\n        )\n        Web_m = trial.suggest_float(\n            \"Web_m\", \n            np.min(X.Web), np.max(X.Web)\n        )\n        Web_b = trial.suggest_float(\n            \"Web_b\", \n            0, 1\n        )\n        Web_c = trial.suggest_float(\n            \"Web_c\", \n            0, 1\n        )     \n        \n        Web_Saturation = pipe_gom_Saturation(\n            K=Web_K,\n            m=Web_m,\n            b=Web_b,\n            c=Web_c\n        )\n        \n    ##Web Carryover\n    \n    if Web_Carryover_func == 'simple':\n        \n        Web_rate = trial.suggest_float(\n            \"Web_rate\", \n            0,1\n        )\n        Web_length = trial.suggest_int(\n            \"Web_length\", \n            1,6\n        )\n        \n        Web_Carryover = pipe_simple_Carryover(\n            length=Web_length,\n            rate=Web_rate\n        )\n        \n    else:\n        \n        Web_rate = trial.suggest_float(\n            \"Web_rate\", \n            0, 1\n        )\n        Web_length = trial.suggest_int(\n            \"Web_length\",\n            1,6\n        )\n        Web_peak = trial.suggest_int(\n            \"Web_peak\",\n            0,2\n        )\n        \n        Web_Carryover = pipe_peak_Carryover(\n            length=Web_length,\n            rate=Web_rate,\n            peak=Web_peak\n        )   \n    \n    # パイプライン化\n    ## 変換器（Adstock）\n    adstock = ColumnTransformer(\n        [\n         ('TVCM_pipe', Pipeline([\n             ('TVCM_carryover', TVCM_Carryover),\n             ('TVCM_saturation', TVCM_Saturation)\n         ]), ['TVCM']),\n         ('Newspaper_pipe', Pipeline([\n             ('Newspaper_carryover', Newspaper_Carryover),\n             ('Newspaper_saturation', Newspaper_Saturation)\n         ]), ['Newspaper']),\n         ('Web_pipe', Pipeline([\n             ('Web_carryover', Web_Carryover),\n             ('Web_saturation', Web_Saturation)\n         ]), ['Web']),\n        ],\n        remainder='passthrough'\n    )\n    \n    ## 説明変数の変換（adstock）→線形回帰モデル（regression）\n    MMM_pipe = Pipeline([\n        ('adstock', adstock),\n        ('regression', Ridge(alpha=alpha))\n    ])\n        \n    #CVによる評価\n    score = cross_val_score(\n        MMM_pipe,\n        X,\n        y,\n        cv=TimeSeriesSplit()\n    )\n    accuracy = score.mean()\n    return accuracy","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 目的関数の最適化を実行する\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective,\n               n_trials=10000,\n               show_progress_bar=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 探索結果\nstudy.best_params","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **モデルの構築と予測**\n- **パイプライン構築**\n    - パイプライン用の、飽和モデルとキャリーオーバー効果の2つの変換器クラスを定義","metadata":{}},{"cell_type":"code","source":"# Pipeline用変換器\n\n## 飽和モデル\nclass Saturation(BaseEstimator, TransformerMixin):\n    \n    # 初期化\n    def __init__(self,func='exp',a=1.0,K=1.0,m=100.0,b=1.0, c=0.1):\n        self.func = func\n        self.a = a\n        self.K = K\n        self.m = m\n        self.b = b\n        self.c = c\n    \n    # 学習\n    def fit(self, X, y=None):\n        return self\n    \n    # 処理（入力→出力）\n    def transform(self, X):\n        if self.func == 'exp':\n            X_ = exp_Saturation(X,\n                                self.a\n                               ).reshape(-1,1)\n        elif self.func == \"logit\":\n            X_ = logit_Saturation(X,\n                                  self.K, \n                                  self.b,\n                                  self.c, \n                                  self.m\n                                 ).reshape(-1,1)\n        else:\n            X_ = gom_Saturation(X,\n                                self.K, \n                                self.b, \n                                self.c, \n                                self.m\n                               ).reshape(-1,1)\n        return X_\n    \n## ラグ効果モデル\nclass Carryover(BaseEstimator, TransformerMixin):\n    # 初期化\n    def __init__(self,func='simple',length=4, peak=1, rate=0.5):\n        self.func = func\n        self.length = length\n        self.peak = peak\n        self.rate = rate\n        \n    # 学習        \n    def fit(self, X, y=None):\n        return self\n    # 処理（入力→出力）\n    def transform(self, X):\n        if self.func == 'peak':\n            X_ = peak_Carryover(X, \n                                self.length, \n                                self.peak, \n                                self.rate)  \n        else:\n            X_ = simple_Carryover(X, \n                                  self.rate, \n                                  self.length)\n            \n        return X_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **2つの変換器でアドストック（Ad Stock）**を表現します。これらの**変換器と学習器（Ridge回帰モデル）をつなげたパイプラインを構築**","metadata":{}},{"cell_type":"code","source":"# Pipelineの設定\n\n## 説明変数の変換部分（adstock）の定義\nadstock = ColumnTransformer(\n    [\n     ('TVCM_pipe', Pipeline([\n                           ('carryover', Carryover()),\n                           ('saturation', Saturation())\n     ]), ['TVCM']),\n     ('Newspaper_pipe', Pipeline([\n                           ('carryover', Carryover()),\n                           ('saturation', Saturation())\n     ]), ['Newspaper']),\n     ('Web_pipe', Pipeline([\n                           ('carryover', Carryover()),\n                           ('saturation', Saturation())\n     ]), ['Web']),\n    ],\n    remainder='passthrough'\n)\n\n## 説明変数の変換（adstock）→線形回帰モデル（regression）(Ridge使用)\nMMM_pipe = Pipeline([\n    ('adstock', adstock),\n    ('regression', Ridge())\n])\n## パイプラインの確認\nset_config(display='diagram')   \nMMM_pipe","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **最適ハイパーパラメータで学習**","metadata":{}},{"cell_type":"code","source":"# 最適ハイパーパラメータ\nbest_params={\n 'regression__alpha': \n    study.best_params.get('alpha'),\n 'adstock__TVCM_pipe__carryover__func': \n    study.best_params.get('TVCM_Carryover_func'),\n 'adstock__TVCM_pipe__carryover__length': \n    study.best_params.get('TVCM_length'),\n 'adstock__TVCM_pipe__carryover__peak': \n    study.best_params.get('TVCM_peak'),\n 'adstock__TVCM_pipe__carryover__rate': \n    study.best_params.get('TVCM_rate'),\n 'adstock__TVCM_pipe__saturation__func': \n    study.best_params.get('TVCM_Saturation_func'),\n 'adstock__TVCM_pipe__saturation__a': \n    study.best_params.get('TVCM_a'),\n 'adstock__TVCM_pipe__saturation__K': \n    study.best_params.get('TVCM_K'),\n 'adstock__TVCM_pipe__saturation__m': \n    study.best_params.get('TVCM_m'),\n 'adstock__TVCM_pipe__saturation__b': \n    study.best_params.get('TVCM_b'),\n 'adstock__TVCM_pipe__saturation__c': \n    study.best_params.get('TVCM_c'),\n 'adstock__Newspaper_pipe__carryover__func': \n    study.best_params.get('Newspaper_Carryover_func'),\n 'adstock__Newspaper_pipe__carryover__length': \n    study.best_params.get('Newspaper_length'),\n 'adstock__Newspaper_pipe__carryover__peak': \n    study.best_params.get('Newspaper_peak'),\n 'adstock__Newspaper_pipe__carryover__rate': \n    study.best_params.get('Newspaper_rate'),\n 'adstock__Newspaper_pipe__saturation__func': \n    study.best_params.get('Newspaper_Saturation_func'),\n 'adstock__Newspaper_pipe__saturation__a': \n    study.best_params.get('Newspaper_a'),\n 'adstock__Newspaper_pipe__saturation__K': \n    study.best_params.get('Newspaper_K'),\n 'adstock__Newspaper_pipe__saturation__m': \n    study.best_params.get('Newspaper_m'),\n 'adstock__Newspaper_pipe__saturation__b': \n    study.best_params.get('Newspaper_b'),\n 'adstock__Newspaper_pipe__saturation__c': \n    study.best_params.get('Newspaper_c'),\n 'adstock__Web_pipe__carryover__func':\n    study.best_params.get('Web_Carryover_func'),\n 'adstock__Web_pipe__carryover__length': \n    study.best_params.get('Web_length'),\n 'adstock__Web_pipe__carryover__peak': \n    study.best_params.get('Web_peak'),\n 'adstock__Web_pipe__carryover__rate': \n    study.best_params.get('Web_rate'),\n 'adstock__Web_pipe__saturation__func': \n    study.best_params.get('Web_Saturation_func'),\n 'adstock__Web_pipe__saturation__a': \n    study.best_params.get('Web_a'),\n 'adstock__Web_pipe__saturation__K': \n    study.best_params.get('Web_K'),\n 'adstock__Web_pipe__saturation__m': \n    study.best_params.get('Web_m'),\n 'adstock__Web_pipe__saturation__b': \n    study.best_params.get('Web_b'),\n 'adstock__Web_pipe__saturation__c': \n    study.best_params.get('Web_c'),\n}\n\n# パイプラインのインスタンス\nMMM_pipe_best = MMM_pipe.set_params(**best_params)\n\n# 全データで学習\nMMM_pipe_best.fit(X, y)\n\n# R2（決定係数）\nMMM_pipe_best.score(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **予測の実施**","metadata":{}},{"cell_type":"code","source":"# 予測の実施\n\n# 目的変数y（売上）の予測\npred = pd.DataFrame(MMM_pipe_best.predict(X),\n                    index=X.index,\n                    columns=['y'])\n\n# 各媒体による売上の予測\n## 値がすべて0の説明変数\nX_ = X.copy()\nX_.iloc[:,:]=0\n\n## Base\npred['Base'] = MMM_pipe_best.predict(X_)\n\n## 媒体\nfor i in range(len(X.columns)):\n    X_.iloc[:,:]=0\n    X_.iloc[:,i]=X.iloc[:,i]\n    pred[X.columns[i]] = MMM_pipe_best.predict(X_) - pred['Base']\n    \nprint(pred) #確認","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **貢献度とマーケティングROIの算定**","metadata":{}},{"cell_type":"code","source":"# 貢献度の算定\n\n# 予測値の補正\ncorrection_factor = y.div(pred['y'], axis=0)   #補正係数\npred_adj = pred.mul(correction_factor, axis=0) #補正後の予測値\n\n# 各媒体の貢献度だけ抽出\ncontribution = pred_adj[['Base', 'Web', 'Newspaper', 'TVCM']]\nprint(contribution.head())\n\n# グラフ化\nax = (contribution\n      .plot.area(\n          ylabel='Sales',\n          xlabel='Week')\n     )\nhandles, labels = ax.get_legend_handles_labels()\nax.legend(handles[::-1], labels[::-1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **貢献度の構成比の算出**","metadata":{}},{"cell_type":"code","source":"# 貢献度の構成比の算出\n\n# 媒体別の貢献度の合計\ncontribution_sum = contribution.sum(axis=0)\n\n# 集計結果の出力\nprint('売上貢献度（円）:\\n', \n      contribution_sum, \n      sep=''\n     )\nprint()\nprint('売上貢献度（構成比）:\\n', \n      contribution_sum/contribution_sum.sum(), \n      sep=''\n     )\n\n# グラフ化\ncontribution_sum.plot.pie(fontsize=24)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **マーケティングROIの算定**","metadata":{}},{"cell_type":"code","source":"# 各媒体のコストの合計\ncost_sum = X.sum(axis=0)\n\n# 各媒体のROIの計算\nROI = (contribution_sum.drop('Base', axis=0) - cost_sum)/cost_sum\nprint('ROI:\\n', ROI, sep='')\n\n# グラフ化\nROI.plot.bar(fontsize=24)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n<a id=\"PCR\"></a>\n## <p>**主成分分析回帰(PCR)モデル**</p>\n- 多くの広告・販促は一定の期間に集中し実施する事が多いので、相関が発生し問題が発生する。この対策の一つとして正則化付き線形回帰と**主成分分析回帰(PCR)**を使用する\n    - **主成分分析回帰(PCR)**、**元の説明変数X**に対し**主成分分析**を実施し、**主成分得点(変換後のデータ)**を求め、その**主成分得点**を使い、**線形回帰モデル**を構築する手法。\n    - 要は、**主成分分析×線形回帰**という**２つの数理モデルを組み合わせたもの** が、主成分回帰(PCR)\n- **主成分分析(PCR)について**\n    - PCAは訓練セットの分散を最大限に維持する軸を見つけ出す。\n        - 訓練セットの主成分を見つける為には、訓練セット行列$XをU W V^{T}$の3行列のドット積に分解できる\n        - **特異値分解(SVD：singular value decomposition)**という**標準的な行列分解(matrix factorization)テクニック**ここで、Vにはすべての主成分を定義する単位ベクトルを含む\n        - **PCAは、データセットが原点を中心としてセンタリングされていることを前提としている。**\n            - **scikit-learnのPCAは自動でデータのセンタリングをしてくれる**。他のライブラリを使用する場合には、データのセンタリングが自動かどうかに注意する。\n        - 全ての主成分がみつかったら、最初のd個の成分が定義する超平面に射影すれば、データセットをd次元に**次元削減**できる。\n            - これで超平面を選択すれば、射影しても分散が最大限に維持されることが保証される。\n    - **因子寄与率**\n        - **個々の主成分に沿ったデータセットの分散の分散全体に対する割合**\n        - $from sklearn.decomposition import PCA$では、$explained_variance_ratio_ $属性から、個々の主成分の**因子寄与率(explained variance ratio)**が得られる。\n            - $PCA(n_components=2)$の場合、2次元への射影になるので、因子寄与率は2であり、各値はデータセットの分散を示す。\n    - **適切な次数の選択**\n        - **次数をいくつまで削減するか**を無作為に選択するよりも、各次元に沿った因子寄与率の合計が十分な割合(例：95%)になるように次数を選択する。\n            - 可視化の為の次数の選択であれば2か3次元でよい。(スイスロール)\n            - 分散を維持する際に、オリジナルのデータセットのサイズが減る点に注意する。これは**圧縮**\n                - **圧縮(率)**によって分類アルゴリズム(SVMなど)が大幅にスピードアップされる\n            - **95%の分散を維持する**\n                - $cumsum = np.cumsum(pca.explained_variance_ratio_)$\n                - $d = np.argmax(cumsum >= 0.95) + 1$\n            - **因子寄与率のプロット**\n                - 上記の$cumsum$をプロットする\n                    - 因子寄与率の伸びが鈍化する屈曲点があるので、これがそのデータセットの本来の次数だと考えられる。\n            - **PCA射影の逆変換**\n                - 逆変換を行う事によって、次元削減されたデータセットを元の次元サイズに再構築することも可能。\n                    - 95%は5%のデータを削除しているので、元のデータが戻るわけではない。この５％は消失している。**元のデータに近いものが得られる**\n                    - オリジナルデータと再構築されたデータの平均二乗距離を**再構築誤差(reconstruction error)**\n                    - $pca = PCA(n_components=150)$\n                    - $X_reduced = pca.fit_transform(X_train)$\n                    - $X_recovered = pca.inverse_transform(X_reduced)$ ← **再構築誤差**実行\n- **主成分分析(PCR)**を挟む理由\n    - **データセットの次元を削減する**\n    - **主成分同士の相関が小さい**\n        - **主成分分析**を実施することで、**元の説明変数Xを主成分に変換**する。\n            - **主成分分析**によって生み出された**主成分**は、**お互いの相関は非常に小さいもの**となる\n        - **説明変数Xの変数の数**より少なくて済む。これが**次元削減**\n- **主成分分析(PCR)の種類**\n    - **ランダム化PCA**\n        - **scikit-learnのsvd_solver=\"randomized\"**\n        - 最初のd個の主成分の概数を高速に見つけ出してくる**ランダム化PCA**確立的アルゴリズムを使用。\n        - $O(m×n^{2})+O(n^{3})だが、ランダム化PCAはO(m×d^{2})+O(d^{3})$である為、dがnよりもかなり小さいときには大幅に高速になる\n            - $rand_pca = PCA(n_components=150, svd_solver=\"randomized\")$\n            - デフォルトは$svd_solver=\"auto\"$になっている。ｍかｎが500よりも大きく、ｄがｍかｎの80%よりも小さければ、自動的にランダム化PCAを使用する\n            - **特異値分解**を強制する場合には$svd_solver=\"full\"$っを指定する\n    - **逐次学習型PCA(IPCA)**\n        - 通常のPCAの実装には、**訓練セット全体がメモリに収まっていなければアルゴリズムを実行不可能**という問題がある。\n        - **訓練セットをミニバッチに分解し、1度に１つずつミニバッチを渡す**\n            - **大規模な訓練セットを使用する場合**や**PCAをオンライン実行(新インスタンス時の実行)**したい場合に有効\n            - $IncrementalPCA$\n            - Numpyのmemmapを使用。\n                - ディスク上のバイナリファイルに格納された大規模な配列がまるでメモリ内にあるかのように操作する。\n                - データが必要になった時に必要なだけのデータをメモリにロードする\n                - $memm = np.memmap(filename, dtype=\"float32\", mode=\"readonly\", shape=(m, n))$\n                - $batch_size = m // n_batches$\n                - $inc_pca = IncrementalPCA(n_components=150, batch_size=batch_size)$\n                - $inc_pca.fit(memm)$\n    - **カーネルPCA**\n        - **インスタンスを特徴量空間**にマッピング。**カーネルトリック**を使用。\n        - カーネルトリックを使用すれば、PCAが次元削減のために**複雑な非線形射影**を実行できる\n        - kPCAは、射影後にもインスタンスのクラスタをうまく保存でき、曲がりくねった多様体に近接するデータセットの展開にも使える\n            - **ガウスRBFカーネル**\n                - $from sklearn.decomposition import KernelPCA$\n                - $rbf_pca = KernelPCA(n_components=2, kernel=\"rbf\", gamma=0.04)$\n                - $X_reduced = rbf_pca.fit_transform(X)$\n            - **カーネルの選択とハイパーパラメータ調整**\n                - **Optuna**を使用するのが早い\n                - Otptunaを使用できない環境であれば**GridSearchやRand**を使用する。\n                - **kernel**\n                    - $\"rbf\", \"kernel\"$\n            - **再構築プレイメージ**\n                - 再構築実行\n                    - $rbf_pca = KernelPCA(n_components=2, kernel=\"rbf\", gamma=0.04, fit_inverse_transform=True)$\n                    - $rbf_pca.fit_transform(X)$\n                    - $rbf_pca.inverse_transform(X_reduced)$\n    - **LLE(局所線形埋め込み法)**\n        - 強力な**非線形次元削減(NLDR：nonlinear dimentionality reducation)**\n        - 他のアルゴリズムとは異なり、**射影に依存しない多様体学習テクニック**\n            - 個々の訓練インスタンスが最近傍インスタンスと線形にどのような関係になるかを測定し、局所的な関係がもっとも保存される訓練セットの低次元表現を探す。\n            - **特にノイズがあまり多くない時には、曲がりくねった多様体の展開で力を発揮する**\n                - $LocallyLinearEmbedding(n_components=2, n_neighbors=10)$\n                - LLEの最初のステップは、**制約付き最適化問題**\n            - **LLEの計算量**\n                - k個の最近傍インスタンスを見つける為に、$O(m \\log(m)n \\log(k))$\n                - 重みの最適化のために$O(mnk^{3})$\n                - 低次元表現の構築のため$O(dm^{2})$、$m^{2}$で大規模なデータセットへのスケーラビリティは低い\n    - **ランダム射影**\n        - **ランダム線形射影**\n        - 次元削減の品質はインスタンス数とターゲット次元によって左右されるが、初期次元の影響を受けない\n    - **多次元尺度法(MDS)**\n        - インスタンス間の距離を維持しようとしながら次元削減を行う\n    - **Isomap**\n        - 個々のインスタンスと複数の最近棒インスタンスを結んでグラフを作り、インスタンス間の**測地距離**を可能な限り維持しながら次元を削減する\n    - **t-SNE**\n        - t分布確率的近傍埋め込み法は、類似するインスタンスを近くに保ち、似ていないインスタンスを遠くに遠ざけようとしながら次元を削減する。\n        - **可視化、特に高次空間のインスタンスのクラスタを視覚化するために使われることが多い。(MNISTの2次元可視化のような)**\n    - **LDA**\n        - これは**本来分類アルゴリズム**だが、訓練中にはクラスをもっとも特徴的に分ける軸を学習し、それらの軸を使ってデータを射影する超空間を定義する。\n        - このため、**LDAはSVM分類器などその他の分類アルゴリズムを実行する前の次元削減テクニックとして優れている**\n- **主成分回帰(PCR)のハイパーパラメータ**\n    - **主成分数**\n        - 主成分数を決める方法は様々ある。\n- **主成分分析(PCR)モデルのデメリット**\n    - モデルの説明力や予測精度は悪化する\n- [**主成分分析を使用した、AdStockでの最適な組み合わせ**](#rag_sat)\n    - **ラグモデル**\n        - 定率減少型ラグ効果モデル（simple_Carryover）\n        - ピーク可変型ラグ効果モデル（peak_Carryover）\n    - **飽和モデル**\n        - 指数型飽和モデル（exp_Saturation）\n        - ロジスティック型飽和モデル（logit_Saturation）\n        - ゴンペルツ型飽和モデル（gom_Saturation）","metadata":{}},{"cell_type":"code","source":"!pip install optuna","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optuna\nimport numpy as np\nimport pandas as pd\n\nfrom scipy.signal import convolve2d\n\n# Base\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\n# Scaling\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer\n\n# Model\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LinearRegression\n\n# SKl\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import TimeSeriesSplit, cross_val_score\nfrom sklearn import set_config\n\n# Optuna\nfrom optuna.integration import OptunaSearchCV\nfrom optuna.distributions import IntUniformDistribution, UniformDistribution, IntDistribution, FloatDistribution\n\n# Plot\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot') #グラフスタイル\nplt.rcParams['figure.figsize'] = [12, 9] # グラフサイズ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DataLoad\nurl = 'https://www.salesanalytics.co.jp/4zdt'\ndf = pd.read_csv(url,\n                 parse_dates=['Week'],\n                 index_col='Week'\n                )\n\n# DataInfo\nprint(df.info()) #変数の情報\nprint(df.head()) #データの一部\n\n# 説明変数Xと目的変数yに分解\nX = df.drop(columns=['Sales'])\ny = df['Sales']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n### **基礎 : PCR**\n- **パイプライン化**\n- **主成分回帰（PCR）**は、\n    - 元の説明変数Xを標準化し\n    - 標準化した値を利用し主成分分析し\n        - 標準化とは、元のデータを平均で引き標準偏差で割ったもの\n        - sklearn : StandardScaler\n    - 主成分得点と目的変数yで線形回帰モデルを構築\n- **パイプライン構築**\n    - **標準化(StandardScaler)**\n    - **主成分分析(PCA)**\n    - **Model：線形回帰(LinearRegression)**","metadata":{}},{"cell_type":"code","source":"# Pipeline構築\n\n# 標準化→主成分分析→線形回帰\nMMM = Pipeline([\n    ('SS', StandardScaler()), # < PCAが既にセンタリングするのにいるのか？\n    ('PCA', PCA()),\n    ('regression', LinearRegression())\n])\n\n## パイプラインの確認\nset_config(display='diagram')   \nMMM","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **ハイパーパラメータ探索**\n- **主成分回帰（PCR）**の最適な**主成分の数**の値を探索；","metadata":{}},{"cell_type":"code","source":"# ハイパーパラメータ探索\n#\n# 探索するハイパーパラメータ範囲の設定\nparams = {\n 'PCA__n_components':IntUniformDistribution(1, 3), # IntDistribution()\n}\n# ハイパーパラメータ探索の設定\noptuna_search = OptunaSearchCV(\n    estimator=MMM,\n    param_distributions=params,\n    n_trials=1000,\n    cv=TimeSeriesSplit(),\n    random_state=123,\n)\n# 探索実施\noptuna_search.fit(X, y)\n# 探索結果\noptuna_search.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 最適な**主成分の数**\n- **主成分の数**に設定し、MMMを全データで構築\n- **最適ハイパーパラメータで学習**","metadata":{}},{"cell_type":"code","source":"# 最適ハイパーパラメータで学習\n\n# パイプラインのインスタンス\nMMM_best = MMM.set_params(**optuna_search.best_params_)\n# 全データで学習\nMMM_best.fit(X, y)\n# R2（決定係数）\nMMM_best.score(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **予測の実施**","metadata":{}},{"cell_type":"code","source":"# 予測の実施\n\n# 目的変数y（売上）の予測\npred = pd.DataFrame(MMM_best.predict(X),\n                    index=X.index,\n                    columns=['y'])\n\n# 各媒体による売上の予測\n## 値がすべて0の説明変数\nX_ = X.copy()\nX_.iloc[:,:]=0\n\n## Base\npred['Base'] = MMM_best.predict(X_)\n\n## 媒体\nfor i in range(len(X.columns)):\n    X_.iloc[:,:]=0\n    X_.iloc[:,i]=X.iloc[:,i]\n    pred[X.columns[i]] = MMM_best.predict(X_) - pred['Base']\n    \nprint(pred) #確認","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 貢献度とマーケティングROIの算定\n- 貢献度の算定","metadata":{}},{"cell_type":"code","source":"# 貢献度の算定\n\n# 予測値の補正\ncorrection_factor = y.div(pred['y'], axis=0)   #補正係数\npred_adj = pred.mul(correction_factor, axis=0) #補正後の予測値\n\n# 各媒体の貢献度だけ抽出\ncontribution = pred_adj[['Base', 'Web', 'Newspaper', 'TVCM']]\nprint(contribution.head()) #確認\n\n# グラフ化\nax = (contribution\n      .plot.area(\n          ylabel='Sales',\n          xlabel='Week')\n     )\n\nhandles, labels = ax.get_legend_handles_labels()\nax.legend(handles[::-1], labels[::-1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **貢献度の構成比の算出**","metadata":{}},{"cell_type":"code","source":"# 貢献度の構成比\n\n# 媒体別の貢献度の合計\ncontribution_sum = contribution.sum(axis=0)\n\n# 集計結果の出力\nprint('売上貢献度（円）:\\n', \n      contribution_sum, \n      sep=''\n     )\nprint()\nprint('売上貢献度（構成比）:\\n', \n      contribution_sum/contribution_sum.sum(), \n      sep=''\n     )\n\n# グラフ化\ncontribution_sum.plot.pie(fontsize=24)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **マーケティングROIの算定**","metadata":{}},{"cell_type":"code","source":"# マーケティングROIの算定\n#\n# 各媒体のコストの合計\ncost_sum = X.sum(axis=0)\n# 各媒体のROIの計算\nROI = (contribution_sum.drop('Base', axis=0) - cost_sum)/cost_sum\nprint('ROI:\\n', ROI, sep='') #確認\n# グラフ化\nROI.plot.bar(fontsize=24)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n<a id=\"rag_sat\"></a>\n## <p>**最適な組み合わせを使用したAdStock**</p>\n- **ハイパーパラメータ探索**\n- **主成分回帰モデル（PCR）**の最適な**主成分の数**と、**ラグ効果**や**飽和効果**の**ハイパーパラメータ**を探索","metadata":{}},{"cell_type":"markdown","source":"- **飽和モデル + 変換器**","metadata":{}},{"cell_type":"code","source":"# 飽和モデル\n\n### 指数型飽和モデル（exp_Saturation）\ndef exp_Saturation(X: np.ndarray,a):\n    return 1 - np.exp(-a*X)\n\n### ロジスティック型飽和モデル（logit_Saturation）\ndef logit_Saturation(X: np.ndarray,K,b,c,m):\n    return K/(1+b*np.exp(-c*(X-m)))\n\n### ゴンペルツ型飽和モデル（gom_Saturation）\ndef gom_Saturation(X: np.ndarray,K,b,c,m):\n    return K*(b**np.exp(-c*(X-m)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## 変換器\n\n\n### 指数型飽和モデル（exp_Saturation）\nclass pipe_exp_Saturation(BaseEstimator, TransformerMixin):\n    \n    # 初期化\n    def __init__(self,a=1.0):\n        self.a = a\n    \n    # 学習\n    def fit(self, X, y=None):\n        return self\n    \n    # 処理（入力→出力）\n    def transform(self, X):\n        X_ = exp_Saturation(X,\n                            self.a\n                           ).reshape(-1,1)\n        return X_\n\n\n### ロジスティック型飽和モデル（logit_Saturation）\nclass pipe_logit_Saturation(BaseEstimator, TransformerMixin):\n    \n    # 初期化\n    def __init__(self,K=1.0,m=100.0,b=1.0, c=0.1):\n        self.K = K\n        self.m = m\n        self.b = b\n        self.c = c\n    \n    # 学習\n    def fit(self, X, y=None):\n        return self\n    \n    # 処理（入力→出力）\n    def transform(self, X):\n        X_ = logit_Saturation(X,\n                              self.K, \n                              self.b, \n                              self.c, \n                              self.m\n                             ).reshape(-1,1)\n        return X_\n\n\n### ゴンペルツ型飽和モデル（gom_Saturation）\nclass pipe_gom_Saturation(BaseEstimator, TransformerMixin):\n    \n    # 初期化\n    def __init__(self,K=1.0,m=100.0,b=1.0,c=0.1):\n        self.K = K\n        self.m = m\n        self.b = b\n        self.c = c\n    \n    # 学習\n    def fit(self, X, y=None):\n        return self\n    \n    # 処理（入力→出力）\n    def transform(self, X):\n        X_ = gom_Saturation(X,\n                            self.K, \n                            self.b, \n                            self.c, \n                            self.m\n                           ).reshape(-1,1)\n        return X_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **ラグモデル+変換器**","metadata":{}},{"cell_type":"code","source":"# ラグ効果モデル\n\n\n### 定率減少型ラグ効果モデル（simple_Carryover）\ndef simple_Carryover(X: np.ndarray, rate, length):\n    \n    filter = (\n        rate ** np.arange(length)\n    ).reshape(-1, 1) \n    \n    convolution = convolve2d(X, filter)\n    \n    if length > 1 : convolution = convolution[: -(length-1)]\n        \n    return convolution\n\n\n### ピーク可変型ラグ効果モデル（peak_Carryover）\ndef peak_Carryover(X: np.ndarray, length, peak, rate):\n    X = np.append(np.zeros(length-1), X)\n    \n    Ws = np.zeros(length)\n    \n    for l in range(length):\n        W = rate**((l-peak)**2)\n        Ws[length-1-l] = W\n    \n    carryover_X = []\n    \n    for i in range(length-1, len(X)):\n        X_array = X[i-length+1:i+1]\n        Xi = sum(X_array * Ws)/sum(Ws)\n        carryover_X.append(Xi)\n        \n    return np.array(carryover_X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## 変換器の定義\n\n\n### 定率減少型ラグ効果モデル　※ピークが広告など投入時（simple_Carryover）\nclass pipe_simple_Carryover(BaseEstimator, TransformerMixin):\n    # 初期化\n    def __init__(self,length=4,rate=0.5):\n        self.length = length\n        self.rate = rate\n        \n    # 学習        \n    def fit(self, X, y=None):\n        return self\n    # 処理（入力→出力）\n    def transform(self, X):\n        X_ = simple_Carryover(X, \n                              self.rate, \n                              self.length\n                             )\n        return X_\n\n\n### ピーク可変型ラグ効果モデル（peak_Carryover）\nclass pipe_peak_Carryover(BaseEstimator, TransformerMixin):\n    # 初期化\n    def __init__(self,length=4,peak=1,rate=0.5):\n        self.length = length\n        self.peak = peak\n        self.rate = rate\n        \n    # 学習        \n    def fit(self, X, y=None):\n        return self\n    # 処理（入力→出力）\n    def transform(self, X):\n        X_ = peak_Carryover(X, \n                            self.length, \n                            self.peak, \n                            self.rate\n                           ) \n        return X_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **Optuna**で利用する**目的関数**を定義する","metadata":{}},{"cell_type":"code","source":"# 目的関数の設定\ndef objective(trial):\n    \n    #PCA\n    n_components = trial.suggest_int(\n        \"n_components\",\n        1, 3\n    )\n    \n    #TVCM\n    \n    ##TVCM Adstock func\n    \n    TVCM_Saturation_func = trial.suggest_categorical(\n        \"TVCM_Saturation_func\",\n        [\"exp\", \"logit\",\"gom\"]\n    )\n    \n    TVCM_Carryover_func = trial.suggest_categorical(\n        \"TVCM_Carryover_func\",\n        [\"simple\", \"peak\"]\n    )\n    \n    ##TVCM_Saturation\n    \n    if TVCM_Saturation_func == 'exp':\n        \n        TVCM_a = trial.suggest_float(\n            \"TVCM_a\", \n            0, 0.01\n        )\n        \n        TVCM_Saturation = pipe_exp_Saturation(a=TVCM_a)\n        \n    elif TVCM_Saturation_func == 'logit':\n        \n        TVCM_K = trial.suggest_float(\n            \"TVCM_K\", \n            np.min(X.TVCM), np.max(X.TVCM)*2\n        )\n        TVCM_m = trial.suggest_float(\n            \"TVCM_m\",\n            np.min(X.TVCM), np.max(X.TVCM)\n        )\n        TVCM_b = trial.suggest_float(\n            \"TVCM_b\",\n            0, 10\n        )\n        TVCM_c = trial.suggest_float(\n            \"TVCM_c\",\n            0, 1\n        )\n        \n        TVCM_Saturation = pipe_logit_Saturation(\n            K=TVCM_K,\n            m=TVCM_m,\n            b=TVCM_b,\n            c=TVCM_c\n        )\n        \n    else:\n        \n        TVCM_K = trial.suggest_float(\n            \"TVCM_K\", \n            np.min(X.TVCM), \n            np.max(X.TVCM)*2\n        )\n        TVCM_m = trial.suggest_float(\n            \"TVCM_m\", \n            np.min(X.TVCM), \n            np.max(X.TVCM)\n        )\n        TVCM_b = trial.suggest_float(\n            \"TVCM_b\", \n            0, 1\n        )\n        TVCM_c = trial.suggest_float(\n            \"TVCM_c\", \n            0, 1\n        )     \n        \n        TVCM_Saturation = pipe_gom_Saturation(\n            K=TVCM_K,\n            m=TVCM_m,\n            b=TVCM_b,\n            c=TVCM_c\n        )\n        \n    ##TVCM Carryover\n    \n    if TVCM_Carryover_func == 'simple':\n        \n        TVCM_rate = trial.suggest_float(\n            \"TVCM_rate\", \n            0,1\n        )\n        TVCM_length = trial.suggest_int(\n            \"TVCM_length\", \n            1,6\n        )\n        \n        TVCM_Carryover = pipe_simple_Carryover(\n            length=TVCM_length,\n            rate=TVCM_rate\n        )\n        \n    else:\n        \n        TVCM_rate = trial.suggest_float(\n            \"TVCM_rate\", \n            0, 1\n        )\n        TVCM_length = trial.suggest_int(\n            \"TVCM_length\",\n            1,6\n        )\n        TVCM_peak = trial.suggest_int(\n            \"TVCM_peak\",\n            0,2\n        )\n        \n        TVCM_Carryover = pipe_peak_Carryover(\n            length=TVCM_length, \n            rate=TVCM_rate,\n            peak=TVCM_peak\n        )   \n    #Newspaper\n    \n    ##Newspaper Adstock func\n    \n    Newspaper_Saturation_func = trial.suggest_categorical(\n        \"Newspaper_Saturation_func\",\n        [\"exp\", \"logit\",\"gom\"]\n    )\n    \n    Newspaper_Carryover_func = trial.suggest_categorical(\n        \"Newspaper_Carryover_func\",\n        [\"simple\", \"peak\"]\n    )\n    \n    ##Newspaper_Saturation\n    \n    if Newspaper_Saturation_func == 'exp':\n        \n        Newspaper_a = trial.suggest_float(\n            \"Newspaper_a\", \n            0, 0.01\n        )\n        \n        Newspaper_Saturation = pipe_exp_Saturation(a=Newspaper_a)\n        \n    elif Newspaper_Saturation_func == 'logit':\n        \n        Newspaper_K = trial.suggest_float(\n            \"Newspaper_K\",\n            np.min(X.Newspaper), np.max(X.Newspaper)*2\n        )\n        Newspaper_m = trial.suggest_float(\n            \"Newspaper_m\", \n            np.min(X.Newspaper), np.max(X.Newspaper)\n        )\n        Newspaper_b = trial.suggest_float(\n            \"Newspaper_b\", \n            0, 10\n        )\n        Newspaper_c = trial.suggest_float(\n            \"Newspaper_c\", \n            0, 1\n        )\n        \n        Newspaper_Saturation = pipe_logit_Saturation(\n            K=Newspaper_K,\n            m=Newspaper_m,\n            b=Newspaper_b,\n            c=Newspaper_c\n        )\n        \n    else:\n        \n        Newspaper_K = trial.suggest_float(\n            \"Newspaper_K\", \n            np.min(X.Newspaper), np.max(X.Newspaper)*2\n        )\n        Newspaper_m = trial.suggest_float(\n            \"Newspaper_m\", \n            np.min(X.Newspaper), np.max(X.Newspaper)\n        )\n        Newspaper_b = trial.suggest_float(\n            \"Newspaper_b\", \n            0, 1\n        )\n        Newspaper_c = trial.suggest_float(\n            \"Newspaper_c\", \n            0, 1\n        )     \n        \n        Newspaper_Saturation = pipe_gom_Saturation(\n            K=Newspaper_K,\n            m=Newspaper_m,\n            b=Newspaper_b,\n            c=Newspaper_c\n        )\n        \n    ##Newspaper Carryover\n    \n    if Newspaper_Carryover_func == 'simple':\n        \n        Newspaper_rate = trial.suggest_float(\n            \"Newspaper_rate\", \n            0,1\n        )\n        Newspaper_length = trial.suggest_int(\n            \"Newspaper_length\", \n            1,6\n        )\n        \n        Newspaper_Carryover = pipe_simple_Carryover(\n            length=Newspaper_length,\n            rate=Newspaper_rate\n        )\n        \n    else:\n        \n        Newspaper_rate = trial.suggest_float(\n            \"Newspaper_rate\", \n            0, 1\n        )\n        Newspaper_length = trial.suggest_int(\n            \"Newspaper_length\",\n            1,6\n        )\n        Newspaper_peak = trial.suggest_int(\n            \"Newspaper_peak\",\n            0,2\n        )\n        \n        Newspaper_Carryover = pipe_peak_Carryover(\n            length=Newspaper_length,\n            rate=Newspaper_rate,\n            peak=Newspaper_peak\n        )\n            \n    #Web\n    \n    ##Web Adstock func\n    \n    Web_Saturation_func = trial.suggest_categorical(\n        \"Web_Saturation_func\",\n        [\"exp\", \"logit\",\"gom\"]\n    )\n    \n    Web_Carryover_func = trial.suggest_categorical(\n        \"Web_Carryover_func\",\n        [\"simple\", \"peak\"]\n    )\n    \n    ##Web_Saturation\n    \n    if Web_Saturation_func == 'exp':\n        \n        Web_a = trial.suggest_float(\n            \"Web_a\", \n            0, 0.01\n        )\n        \n        Web_Saturation = pipe_exp_Saturation(a=Web_a)\n        \n    elif Web_Saturation_func == 'logit':\n        \n        Web_K = trial.suggest_float(\n            \"Web_K\", \n            np.min(X.Web), np.max(X.Web)*2\n        )\n        Web_m = trial.suggest_float(\n            \"Web_m\", \n            np.min(X.Web), np.max(X.Web)\n        )\n        Web_b = trial.suggest_float(\n            \"Web_b\", \n            0, 10\n        )\n        Web_c = trial.suggest_float(\n            \"Web_c\", \n            0, 1\n        )\n        \n        Web_Saturation = pipe_logit_Saturation(\n            K=Web_K,\n            m=Web_m,\n            b=Web_b,\n            c=Web_c\n        )\n        \n    else:\n        \n        Web_K = trial.suggest_float(\n            \"Web_K\", \n            np.min(X.Web), np.max(X.Web)*2\n        )\n        Web_m = trial.suggest_float(\n            \"Web_m\", \n            np.min(X.Web), np.max(X.Web)\n        )\n        Web_b = trial.suggest_float(\n            \"Web_b\", \n            0, 1\n        )\n        Web_c = trial.suggest_float(\n            \"Web_c\", \n            0, 1\n        )     \n        \n        Web_Saturation = pipe_gom_Saturation(\n            K=Web_K,\n            m=Web_m,\n            b=Web_b,\n            c=Web_c\n        )\n        \n    ##Web Carryover\n    \n    if Web_Carryover_func == 'simple':\n        \n        Web_rate = trial.suggest_float(\n            \"Web_rate\", \n            0,1\n        )\n        Web_length = trial.suggest_int(\n            \"Web_length\", \n            1,6\n        )\n        \n        Web_Carryover = pipe_simple_Carryover(\n            length=Web_length,\n            rate=Web_rate\n        )\n        \n    else:\n        \n        Web_rate = trial.suggest_float(\n            \"Web_rate\", \n            0, 1\n        )\n        Web_length = trial.suggest_int(\n            \"Web_length\",\n            1,6\n        )\n        Web_peak = trial.suggest_int(\n            \"Web_peak\",\n            0,2\n        )\n        \n        Web_Carryover = pipe_peak_Carryover(\n            length=Web_length,\n            rate=Web_rate,\n            peak=Web_peak\n        )   \n    \n    # パイプライン化\n    \n    ## 変換器（Adstock）\n    adstock = ColumnTransformer(\n        [\n         ('TVCM_pipe', Pipeline([\n             ('TVCM_carryover', TVCM_Carryover),\n             ('TVCM_saturation', TVCM_Saturation)\n         ]), ['TVCM']),\n         ('Newspaper_pipe', Pipeline([\n             ('Newspaper_carryover', Newspaper_Carryover),\n             ('Newspaper_saturation', Newspaper_Saturation)\n         ]), ['Newspaper']),\n         ('Web_pipe', Pipeline([\n             ('Web_carryover', Web_Carryover),\n             ('Web_saturation', Web_Saturation)\n         ]), ['Web']),\n        ],\n        remainder='passthrough'\n    )\n    ## 説明変数の変換（adstock）→線形回帰モデル（regression）\n    MMM_pipe = Pipeline([\n        ('adstock', adstock),\n        ('SS', StandardScaler()),\n        ('PCA', PCA(n_components)),\n        ('regression', LinearRegression())\n    ])\n        \n    #CVによる評価\n    score = cross_val_score(\n        MMM_pipe,\n        X,\n        y,\n        cv=TimeSeriesSplit()\n    )\n    accuracy = score.mean()\n    return accuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **Pipelineのハイパーパラメータを探索**","metadata":{}},{"cell_type":"code","source":"# 目的関数の最適化を実行する\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective,\n               n_trials=10000,\n               show_progress_bar=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 探索結果\nstudy.best_params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **パイプライン構築**の、**飽和モデル**と**ラグ効果の2つの変換器クラス**を定義\n- **Pipeline用変換器**","metadata":{}},{"cell_type":"code","source":"## 飽和モデル\n\nclass Saturation(BaseEstimator, TransformerMixin):\n    \n    # 初期化\n    def __init__(self,func='exp',a=1.0,K=1.0,m=100.0,b=1.0, c=0.1):\n        self.func = func\n        self.a = a\n        self.K = K\n        self.m = m\n        self.b = b\n        self.c = c\n    \n    # 学習\n    def fit(self, X, y=None):\n        return self\n    \n    # 処理（入力→出力）\n    def transform(self, X):\n        if self.func == 'exp':\n            X_ = exp_Saturation(X,\n                                self.a\n                               ).reshape(-1,1)\n        elif self.func == \"logit\":\n            X_ = logit_Saturation(X,\n                                  self.K, \n                                  self.b,\n                                  self.c, \n                                  self.m\n                                 ).reshape(-1,1)\n        else:\n            X_ = gom_Saturation(X,\n                                self.K, \n                                self.b, \n                                self.c, \n                                self.m\n                               ).reshape(-1,1)\n        return X_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## ラグ効果モデル\nclass Carryover(BaseEstimator, TransformerMixin):\n    # 初期化\n    def __init__(self,func='simple',length=4, peak=1, rate=0.5):\n        self.func = func\n        self.length = length\n        self.peak = peak\n        self.rate = rate\n        \n    # 学習        \n    def fit(self, X, y=None):\n        return self\n    # 処理（入力→出力）\n    def transform(self, X):\n        if self.func == 'peak':\n            X_ = peak_Carryover(X, \n                                self.length, \n                                self.peak, \n                                self.rate)  \n        else:\n            X_ = simple_Carryover(X, \n                                  self.rate, \n                                  self.length)\n            \n        return X_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- この**2つの変換器でアドストック（Ad Stock）**を表現します。これらの**変換器と学習器（PCRモデル）をつなげたパイプラインを構築**\n- **Pipeline**","metadata":{}},{"cell_type":"code","source":"## 説明変数の変換部分（adstock）の定義\nadstock = ColumnTransformer(\n    [\n     ('TVCM_pipe', Pipeline([\n                           ('carryover', Carryover()),\n                           ('saturation', Saturation())\n     ]), ['TVCM']),\n     ('Newspaper_pipe', Pipeline([\n                           ('carryover', Carryover()),\n                           ('saturation', Saturation())\n     ]), ['Newspaper']),\n     ('Web_pipe', Pipeline([\n                           ('carryover', Carryover()),\n                           ('saturation', Saturation())\n     ]), ['Web']),\n    ],\n    remainder='passthrough'\n)\n\n\n## 説明変数の変換（adstock）→線形回帰モデル（regression）\nMMM_pipe = Pipeline([\n    ('adstock', adstock),\n    ('SS', StandardScaler()),\n    ('PCA', PCA()),\n    ('regression', LinearRegression())\n])\n\n\n## パイプラインの確認\nset_config(display='diagram')   \nMMM_pipe","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **最適ハイパーパラメータで学習**","metadata":{}},{"cell_type":"code","source":"# 最適ハイパーパラメータ\nbest_params={\n 'PCA__n_components': \n    study.best_params.get('n_components'),\n 'adstock__TVCM_pipe__carryover__func': \n    study.best_params.get('TVCM_Carryover_func'),\n 'adstock__TVCM_pipe__carryover__length': \n    study.best_params.get('TVCM_length'),\n 'adstock__TVCM_pipe__carryover__peak': \n    study.best_params.get('TVCM_peak'),\n 'adstock__TVCM_pipe__carryover__rate': \n    study.best_params.get('TVCM_rate'),\n 'adstock__TVCM_pipe__saturation__func': \n    study.best_params.get('TVCM_Saturation_func'),\n 'adstock__TVCM_pipe__saturation__a': \n    study.best_params.get('TVCM_a'),\n 'adstock__TVCM_pipe__saturation__K': \n    study.best_params.get('TVCM_K'),\n 'adstock__TVCM_pipe__saturation__m': \n    study.best_params.get('TVCM_m'),\n 'adstock__TVCM_pipe__saturation__b': \n    study.best_params.get('TVCM_b'),\n 'adstock__TVCM_pipe__saturation__c': \n    study.best_params.get('TVCM_c'),\n 'adstock__Newspaper_pipe__carryover__func': \n    study.best_params.get('Newspaper_Carryover_func'),\n 'adstock__Newspaper_pipe__carryover__length': \n    study.best_params.get('Newspaper_length'),\n 'adstock__Newspaper_pipe__carryover__peak': \n    study.best_params.get('Newspaper_peak'),\n 'adstock__Newspaper_pipe__carryover__rate': \n    study.best_params.get('Newspaper_rate'),\n 'adstock__Newspaper_pipe__saturation__func': \n    study.best_params.get('Newspaper_Saturation_func'),\n 'adstock__Newspaper_pipe__saturation__a': \n    study.best_params.get('Newspaper_a'),\n 'adstock__Newspaper_pipe__saturation__K': \n    study.best_params.get('Newspaper_K'),\n 'adstock__Newspaper_pipe__saturation__m': \n    study.best_params.get('Newspaper_m'),\n 'adstock__Newspaper_pipe__saturation__b': \n    study.best_params.get('Newspaper_b'),\n 'adstock__Newspaper_pipe__saturation__c': \n    study.best_params.get('Newspaper_c'),\n 'adstock__Web_pipe__carryover__func':\n    study.best_params.get('Web_Carryover_func'),\n 'adstock__Web_pipe__carryover__length': \n    study.best_params.get('Web_length'),\n 'adstock__Web_pipe__carryover__peak': \n    study.best_params.get('Web_peak'),\n 'adstock__Web_pipe__carryover__rate': \n    study.best_params.get('Web_rate'),\n 'adstock__Web_pipe__saturation__func': \n    study.best_params.get('Web_Saturation_func'),\n 'adstock__Web_pipe__saturation__a': \n    study.best_params.get('Web_a'),\n 'adstock__Web_pipe__saturation__K': \n    study.best_params.get('Web_K'),\n 'adstock__Web_pipe__saturation__m': \n    study.best_params.get('Web_m'),\n 'adstock__Web_pipe__saturation__b': \n    study.best_params.get('Web_b'),\n 'adstock__Web_pipe__saturation__c': \n    study.best_params.get('Web_c'),\n}\n\n# パイプラインのインスタンス\nMMM_pipe_best = MMM_pipe.set_params(**best_params)\n\n# 全データで学習\nMMM_pipe_best.fit(X, y)\n\n# R2（決定係数）\nMMM_pipe_best.score(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **予測の実施**","metadata":{}},{"cell_type":"code","source":"# 予測の実施\n\n# 目的変数y（売上）の予測\npred = pd.DataFrame(MMM_pipe_best.predict(X),\n                    index=X.index,\n                    columns=['y'])\n\n# 各媒体による売上の予測\n## 値がすべて0の説明変数\nX_ = X.copy()\nX_.iloc[:,:]=0\n\n## Base\npred['Base'] = MMM_pipe_best.predict(X_)\n\n## 媒体\nfor i in range(len(X.columns)):\n    X_.iloc[:,:]=0\n    X_.iloc[:,i]=X.iloc[:,i]\n    pred[X.columns[i]] = MMM_pipe_best.predict(X_) - pred['Base']\n    \nprint(pred) #確認","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **貢献度とマーケティングROIの算定**","metadata":{}},{"cell_type":"code","source":"# 貢献度の算定\n\n# 予測値の補正\ncorrection_factor = y.div(pred['y'], axis=0)   #補正係数\npred_adj = pred.mul(correction_factor, axis=0) #補正後の予測値\n\n# 各媒体の貢献度だけ抽出\ncontribution = pred_adj[['Base', 'Web', 'Newspaper', 'TVCM']]\nprint(contribution.head())\n\n# グラフ化\nax = (contribution\n      .plot.area(\n          ylabel='Sales',\n          xlabel='Week')\n     )\nhandles, labels = ax.get_legend_handles_labels()\nax.legend(handles[::-1], labels[::-1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 貢献度の構成比\n\n# 媒体別の貢献度の合計\ncontribution_sum = contribution.sum(axis=0)\n\n# 集計結果の出力\nprint('売上貢献度（円）:\\n', \n      contribution_sum, \n      sep=''\n     )\nprint()\nprint('売上貢献度（構成比）:\\n', \n      contribution_sum/contribution_sum.sum(), \n      sep=''\n     )\n\n# グラフ化\ncontribution_sum.plot.pie(fontsize=24)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **マーケティングROIの算定**","metadata":{}},{"cell_type":"code","source":"# マーケティングROIの算定\n\n# 各媒体のコストの合計\ncost_sum = X.sum(axis=0)\n\n# 各媒体のROIの計算\nROI = (contribution_sum.drop('Base', axis=0) - cost_sum)/cost_sum\nprint('ROI:\\n', ROI, sep='')\n\n# グラフ化\nROI.plot.bar(fontsize=24)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n<a id=\"PLS\"></a>\n## <p>**部分的最小2乗回帰(PLS)**</p>\n- **PLS回帰**とは、部分的最小2乗回帰で、主成分分析回帰PCRとの違い\n    - **PCR** : 主成分が、主成分の分散が最大になるように作成\n    - **PLS** : 主成分が、目的変数Yと主成分の共分散が最大になるように作成\n- **PLS回帰**の違い\n    - **主成分回帰(PCR)**も**PLS回帰**も、**主成分が作られる**ことは同じ\n    - **主成分回帰(PCR)**が説明変数だけで作られるのに対し、**PLS回帰**は目的変数との関係性も考慮して作られる\n- [**PLS回帰のAdStockと最適な組み合わせ**](#AdStock_1)","metadata":{}},{"cell_type":"markdown","source":"- **ハイパーパラメーター：主成分の数**\n    - **PLS回帰**には、**主成分回帰（PCR）**と同様にハイパーパラメータとして**主成分の数**というものがあり、モデル構築者が与える必要がある","metadata":{}},{"cell_type":"code","source":"import optuna\nimport numpy as np\nimport pandas as pd\n\nfrom scipy.signal import convolve2d\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.compose import ColumnTransformer\n\n# PLS\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import TimeSeriesSplit, cross_val_score\nfrom optuna.distributions import IntUniformDistribution, UniformDistribution, IntDistribution, FloatDistribution\nfrom sklearn import set_config\n\n# Optuna\nfrom optuna.integration import OptunaSearchCV\n\n# Plot\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot') #グラフスタイル\nplt.rcParams['figure.figsize'] = [12, 9] # グラフサイズ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# データセット読み込み\nurl = 'https://www.salesanalytics.co.jp/4zdt'\ndf = pd.read_csv(url,\n                 parse_dates=['Week'],\n                 index_col='Week'\n                )\n# データ確認\nprint(df.info()) #変数の情報\nprint(df.head()) #データの一部\n# 説明変数Xと目的変数yに分解\nX = df.drop(columns=['Sales'])\ny = df['Sales']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Hyperparams\n- **PLSの最適な主成分の数の値を探索**","metadata":{}},{"cell_type":"code","source":"# PLS回帰のインスタンス生成\nMMM=PLSRegression()\n\n# 探索するハイパーパラメータ範囲の設定\nparams = {\n 'n_components':IntUniformDistribution(1, 3),\n}\n\n# ハイパーパラメータ探索の設定\noptuna_search = OptunaSearchCV(\n    estimator=MMM,\n    param_distributions=params,\n    n_trials=1000,\n    cv=TimeSeriesSplit(),\n    random_state=123,\n)\n\n# 探索実施\noptuna_search.fit(X, y)\n\n# 探索結果\noptuna_search.best_params_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **最適ハイパーパラメータで学習**","metadata":{}},{"cell_type":"code","source":"# パイプラインのインスタンス\nMMM_best = MMM.set_params(**optuna_search.best_params_)\n\n# 全データで学習\nMMM_best.fit(X, y)\n\n# R2（決定係数）\nMMM_best.score(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **予測の実施**","metadata":{}},{"cell_type":"code","source":"# 予測の実施\n\n# 目的変数y（売上）の予測\npred = pd.DataFrame(MMM_best.predict(X),\n                    index=X.index,\n                    columns=['y'])\n\n# 各媒体による売上の予測\n## 値がすべて0の説明変数\nX_ = X.copy()\nX_.iloc[:,:]=0\n\n## Base\npred['Base'] = MMM_best.predict(X_)\n\n## 媒体\nfor i in range(len(X.columns)):\n    X_.iloc[:,:]=0\n    X_.iloc[:,i]=X.iloc[:,i]\n    pred[X.columns[i]] = MMM_best.predict(X_)[:,0] - pred['Base']\n    \nprint(pred) #確認","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **貢献度とマーケティングROIの算定**","metadata":{}},{"cell_type":"code","source":"# 貢献度の算定\n\n# 予測値の補正\ncorrection_factor = y.div(pred['y'], axis=0)   #補正係数\npred_adj = pred.mul(correction_factor, axis=0) #補正後の予測値\n\n# 各媒体の貢献度だけ抽出\ncontribution = pred_adj[['Base', 'Web', 'Newspaper', 'TVCM']]\nprint(contribution.head()) #確認\n\n# グラフ化\nax = (contribution\n      .plot.area(\n          ylabel='Sales',\n          xlabel='Week')\n     )\nhandles, labels = ax.get_legend_handles_labels()\nax.legend(handles[::-1], labels[::-1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **貢献度の構成比の算出**","metadata":{}},{"cell_type":"code","source":"# 貢献度の構成比\n\n# 媒体別の貢献度の合計\ncontribution_sum = contribution.sum(axis=0)\n\n# 集計結果の出力\nprint('売上貢献度（円）:\\n', \n      contribution_sum, \n      sep=''\n     )\nprint()\nprint('売上貢献度（構成比）:\\n', \n      contribution_sum/contribution_sum.sum(), \n      sep=''\n     )\n\n# グラフ化\ncontribution_sum.plot.pie(fontsize=24)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **マーケティングROIの算定**","metadata":{}},{"cell_type":"code","source":"# マーケティングROIの算定\n\n# 各媒体のコストの合計\ncost_sum = X.sum(axis=0)\n\n# 各媒体のROIの計算\nROI = (contribution_sum.drop('Base', axis=0) - cost_sum)/cost_sum\nprint('ROI:\\n', ROI, sep='') #確認\n\n# グラフ化\nROI.plot.bar(fontsize=24)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n<a id=\"AdStock_1\"></a>\n## <p>**PLSの最適な組み合わせ**</p>\n- **ラグ効果モデル**\n    - 定率減少型ラグ効果モデル（simple_Carryover）\n    - ピーク可変型ラグ効果モデル（peak_Carryover）\n- **飽和モデル**\n    - 指数型飽和モデル（exp_Saturation）\n    - ロジスティック型飽和モデル（logit_Saturation）\n    - ゴンペルツ型飽和モデル（gom_Saturation）","metadata":{}},{"cell_type":"code","source":"# 飽和モデル\n\n### 指数型飽和モデル（exp_Saturation）\ndef exp_Saturation(X: np.ndarray,a):\n    return 1 - np.exp(-a*X)\n\n### ロジスティック型飽和モデル（logit_Saturation）\ndef logit_Saturation(X: np.ndarray,K,b,c,m):\n    return K/(1+b*np.exp(-c*(X-m)))\n\n### ゴンペルツ型飽和モデル（gom_Saturation）\ndef gom_Saturation(X: np.ndarray,K,b,c,m):\n    return K*(b**np.exp(-c*(X-m)))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## 変換器\n\n### 指数型飽和モデル（exp_Saturation）\nclass pipe_exp_Saturation(BaseEstimator, TransformerMixin):\n    \n    # 初期化\n    def __init__(self,a=1.0):\n        self.a = a\n    \n    # 学習\n    def fit(self, X, y=None):\n        return self\n    \n    # 処理（入力→出力）\n    def transform(self, X):\n        X_ = exp_Saturation(X,\n                            self.a\n                           ).reshape(-1,1)\n        return X_\n\n    \n### ロジスティック型飽和モデル（logit_Saturation）\nclass pipe_logit_Saturation(BaseEstimator, TransformerMixin):\n    \n    # 初期化\n    def __init__(self,K=1.0,m=100.0,b=1.0, c=0.1):\n        self.K = K\n        self.m = m\n        self.b = b\n        self.c = c\n    \n    # 学習\n    def fit(self, X, y=None):\n        return self\n    \n    # 処理（入力→出力）\n    def transform(self, X):\n        X_ = logit_Saturation(X,\n                              self.K, \n                              self.b, \n                              self.c, \n                              self.m\n                             ).reshape(-1,1)\n        return X_\n    \n    \n### ゴンペルツ型飽和モデル（gom_Saturation）\nclass pipe_gom_Saturation(BaseEstimator, TransformerMixin):\n    \n    # 初期化\n    def __init__(self,K=1.0,m=100.0,b=1.0,c=0.1):\n        self.K = K\n        self.m = m\n        self.b = b\n        self.c = c\n    \n    # 学習\n    def fit(self, X, y=None):\n        return self\n    \n    # 処理（入力→出力）\n    def transform(self, X):\n        X_ = gom_Saturation(X,\n                            self.K, \n                            self.b, \n                            self.c, \n                            self.m\n                           ).reshape(-1,1)\n        return X_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ラグ効果モデル\n\n\n### 定率減少型ラグ効果モデル（simple_Carryover）\ndef simple_Carryover(X: np.ndarray, rate, length):\n    \n    filter = (\n        rate ** np.arange(length)\n    ).reshape(-1, 1) \n    \n    convolution = convolve2d(X, filter)\n    \n    if length > 1 : convolution = convolution[: -(length-1)]\n        \n    return convolution\n\n\n### ピーク可変型ラグ効果モデル（peak_Carryover）\ndef peak_Carryover(X: np.ndarray, length, peak, rate):\n    X = np.append(np.zeros(length-1), X)\n    \n    Ws = np.zeros(length)\n    \n    for l in range(length):\n        W = rate**((l-peak)**2)\n        Ws[length-1-l] = W\n    \n    carryover_X = []\n    \n    for i in range(length-1, len(X)):\n        X_array = X[i-length+1:i+1]\n        Xi = sum(X_array * Ws)/sum(Ws)\n        carryover_X.append(Xi)\n        \n    return np.array(carryover_X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## 変換器\n\n### 定率減少型ラグ効果モデル　※ピークが広告など投入時（simple_Carryover）\nclass pipe_simple_Carryover(BaseEstimator, TransformerMixin):\n    # 初期化\n    def __init__(self,length=4,rate=0.5):\n        self.length = length\n        self.rate = rate\n        \n    # 学習        \n    def fit(self, X, y=None):\n        return self\n    # 処理（入力→出力）\n    def transform(self, X):\n        X_ = simple_Carryover(X, \n                              self.rate, \n                              self.length\n                             )\n        return X_\n\n    \n### ピーク可変型ラグ効果モデル\nclass pipe_peak_Carryover(BaseEstimator, TransformerMixin):\n    # 初期化\n    def __init__(self,length=4,peak=1,rate=0.5):\n        self.length = length\n        self.peak = peak\n        self.rate = rate\n        \n    # 学習        \n    def fit(self, X, y=None):\n        return self\n    # 処理（入力→出力）\n    def transform(self, X):\n        X_ = peak_Carryover(X, \n                            self.length, \n                            self.peak, \n                            self.rate\n                           ) \n        return X_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 目的関数の設定\ndef objective(trial):\n    \n    #PCA\n    n_components = trial.suggest_int(\n        \"n_components\",\n        1, 3\n    )\n    \n    #TVCM\n    \n    ##TVCM Adstock func\n    \n    TVCM_Saturation_func = trial.suggest_categorical(\n        \"TVCM_Saturation_func\",\n        [\"exp\", \"logit\",\"gom\"]\n    )\n    \n    TVCM_Carryover_func = trial.suggest_categorical(\n        \"TVCM_Carryover_func\",\n        [\"simple\", \"peak\"]\n    )\n    \n    ##TVCM_Saturation\n    \n    if TVCM_Saturation_func == 'exp':\n        \n        TVCM_a = trial.suggest_float(\n            \"TVCM_a\", \n            0, 0.01\n        )\n        \n        TVCM_Saturation = pipe_exp_Saturation(a=TVCM_a)\n        \n    elif TVCM_Saturation_func == 'logit':\n        \n        TVCM_K = trial.suggest_float(\n            \"TVCM_K\", \n            np.min(X.TVCM), np.max(X.TVCM)*2\n        )\n        TVCM_m = trial.suggest_float(\n            \"TVCM_m\",\n            np.min(X.TVCM), np.max(X.TVCM)\n        )\n        TVCM_b = trial.suggest_float(\n            \"TVCM_b\",\n            0, 10\n        )\n        TVCM_c = trial.suggest_float(\n            \"TVCM_c\",\n            0, 1\n        )\n        \n        TVCM_Saturation = pipe_logit_Saturation(\n            K=TVCM_K,\n            m=TVCM_m,\n            b=TVCM_b,\n            c=TVCM_c\n        )\n        \n    else:\n        \n        TVCM_K = trial.suggest_float(\n            \"TVCM_K\", \n            np.min(X.TVCM), \n            np.max(X.TVCM)*2\n        )\n        TVCM_m = trial.suggest_float(\n            \"TVCM_m\", \n            np.min(X.TVCM), \n            np.max(X.TVCM)\n        )\n        TVCM_b = trial.suggest_float(\n            \"TVCM_b\", \n            0, 1\n        )\n        TVCM_c = trial.suggest_float(\n            \"TVCM_c\", \n            0, 1\n        )     \n        \n        TVCM_Saturation = pipe_gom_Saturation(\n            K=TVCM_K,\n            m=TVCM_m,\n            b=TVCM_b,\n            c=TVCM_c\n        )\n        \n    ##TVCM Carryover\n    \n    if TVCM_Carryover_func == 'simple':\n        \n        TVCM_rate = trial.suggest_float(\n            \"TVCM_rate\", \n            0,1\n        )\n        TVCM_length = trial.suggest_int(\n            \"TVCM_length\", \n            1,6\n        )\n        \n        TVCM_Carryover = pipe_simple_Carryover(\n            length=TVCM_length,\n            rate=TVCM_rate\n        )\n        \n    else:\n        \n        TVCM_rate = trial.suggest_float(\n            \"TVCM_rate\", \n            0, 1\n        )\n        TVCM_length = trial.suggest_int(\n            \"TVCM_length\",\n            1,6\n        )\n        TVCM_peak = trial.suggest_int(\n            \"TVCM_peak\",\n            0,2\n        )\n        \n        TVCM_Carryover = pipe_peak_Carryover(\n            length=TVCM_length, \n            rate=TVCM_rate,\n            peak=TVCM_peak\n        )   \n    #Newspaper\n    \n    ##Newspaper Adstock func\n    \n    Newspaper_Saturation_func = trial.suggest_categorical(\n        \"Newspaper_Saturation_func\",\n        [\"exp\", \"logit\",\"gom\"]\n    )\n    \n    Newspaper_Carryover_func = trial.suggest_categorical(\n        \"Newspaper_Carryover_func\",\n        [\"simple\", \"peak\"]\n    )\n    \n    ##Newspaper_Saturation\n    \n    if Newspaper_Saturation_func == 'exp':\n        \n        Newspaper_a = trial.suggest_float(\n            \"Newspaper_a\", \n            0, 0.01\n        )\n        \n        Newspaper_Saturation = pipe_exp_Saturation(a=Newspaper_a)\n        \n    elif Newspaper_Saturation_func == 'logit':\n        \n        Newspaper_K = trial.suggest_float(\n            \"Newspaper_K\",\n            np.min(X.Newspaper), np.max(X.Newspaper)*2\n        )\n        Newspaper_m = trial.suggest_float(\n            \"Newspaper_m\", \n            np.min(X.Newspaper), np.max(X.Newspaper)\n        )\n        Newspaper_b = trial.suggest_float(\n            \"Newspaper_b\", \n            0, 10\n        )\n        Newspaper_c = trial.suggest_float(\n            \"Newspaper_c\", \n            0, 1\n        )\n        \n        Newspaper_Saturation = pipe_logit_Saturation(\n            K=Newspaper_K,\n            m=Newspaper_m,\n            b=Newspaper_b,\n            c=Newspaper_c\n        )\n        \n    else:\n        \n        Newspaper_K = trial.suggest_float(\n            \"Newspaper_K\", \n            np.min(X.Newspaper), np.max(X.Newspaper)*2\n        )\n        Newspaper_m = trial.suggest_float(\n            \"Newspaper_m\", \n            np.min(X.Newspaper), np.max(X.Newspaper)\n        )\n        Newspaper_b = trial.suggest_float(\n            \"Newspaper_b\", \n            0, 1\n        )\n        Newspaper_c = trial.suggest_float(\n            \"Newspaper_c\", \n            0, 1\n        )     \n        \n        Newspaper_Saturation = pipe_gom_Saturation(\n            K=Newspaper_K,\n            m=Newspaper_m,\n            b=Newspaper_b,\n            c=Newspaper_c\n        )\n        \n    ##Newspaper Carryover\n    \n    if Newspaper_Carryover_func == 'simple':\n        \n        Newspaper_rate = trial.suggest_float(\n            \"Newspaper_rate\", \n            0,1\n        )\n        Newspaper_length = trial.suggest_int(\n            \"Newspaper_length\", \n            1,6\n        )\n        \n        Newspaper_Carryover = pipe_simple_Carryover(\n            length=Newspaper_length,\n            rate=Newspaper_rate\n        )\n        \n    else:\n        \n        Newspaper_rate = trial.suggest_float(\n            \"Newspaper_rate\", \n            0, 1\n        )\n        Newspaper_length = trial.suggest_int(\n            \"Newspaper_length\",\n            1,6\n        )\n        Newspaper_peak = trial.suggest_int(\n            \"Newspaper_peak\",\n            0,2\n        )\n        \n        Newspaper_Carryover = pipe_peak_Carryover(\n            length=Newspaper_length,\n            rate=Newspaper_rate,\n            peak=Newspaper_peak\n        )\n            \n    #Web\n    \n    ##Web Adstock func\n    \n    Web_Saturation_func = trial.suggest_categorical(\n        \"Web_Saturation_func\",\n        [\"exp\", \"logit\",\"gom\"]\n    )\n    \n    Web_Carryover_func = trial.suggest_categorical(\n        \"Web_Carryover_func\",\n        [\"simple\", \"peak\"]\n    )\n    \n    ##Web_Saturation\n    \n    if Web_Saturation_func == 'exp':\n        \n        Web_a = trial.suggest_float(\n            \"Web_a\", \n            0, 0.01\n        )\n        \n        Web_Saturation = pipe_exp_Saturation(a=Web_a)\n        \n    elif Web_Saturation_func == 'logit':\n        \n        Web_K = trial.suggest_float(\n            \"Web_K\", \n            np.min(X.Web), np.max(X.Web)*2\n        )\n        Web_m = trial.suggest_float(\n            \"Web_m\", \n            np.min(X.Web), np.max(X.Web)\n        )\n        Web_b = trial.suggest_float(\n            \"Web_b\", \n            0, 10\n        )\n        Web_c = trial.suggest_float(\n            \"Web_c\", \n            0, 1\n        )\n        \n        Web_Saturation = pipe_logit_Saturation(\n            K=Web_K,\n            m=Web_m,\n            b=Web_b,\n            c=Web_c\n        )\n        \n    else:\n        \n        Web_K = trial.suggest_float(\n            \"Web_K\", \n            np.min(X.Web), np.max(X.Web)*2\n        )\n        Web_m = trial.suggest_float(\n            \"Web_m\", \n            np.min(X.Web), np.max(X.Web)\n        )\n        Web_b = trial.suggest_float(\n            \"Web_b\", \n            0, 1\n        )\n        Web_c = trial.suggest_float(\n            \"Web_c\", \n            0, 1\n        )     \n        \n        Web_Saturation = pipe_gom_Saturation(\n            K=Web_K,\n            m=Web_m,\n            b=Web_b,\n            c=Web_c\n        )\n        \n    ##Web Carryover\n    \n    if Web_Carryover_func == 'simple':\n        \n        Web_rate = trial.suggest_float(\n            \"Web_rate\", \n            0,1\n        )\n        Web_length = trial.suggest_int(\n            \"Web_length\", \n            1,6\n        )\n        \n        Web_Carryover = pipe_simple_Carryover(\n            length=Web_length,\n            rate=Web_rate\n        )\n        \n    else:\n        \n        Web_rate = trial.suggest_float(\n            \"Web_rate\", \n            0, 1\n        )\n        Web_length = trial.suggest_int(\n            \"Web_length\",\n            1,6\n        )\n        Web_peak = trial.suggest_int(\n            \"Web_peak\",\n            0,2\n        )\n        \n        Web_Carryover = pipe_peak_Carryover(\n            length=Web_length,\n            rate=Web_rate,\n            peak=Web_peak\n        )   \n    \n    # パイプライン化\n    \n    ## 変換器（Adstock）\n    adstock = ColumnTransformer(\n        [\n         ('TVCM_pipe', Pipeline([\n             ('TVCM_carryover', TVCM_Carryover),\n             ('TVCM_saturation', TVCM_Saturation)\n         ]), ['TVCM']),\n         ('Newspaper_pipe', Pipeline([\n             ('Newspaper_carryover', Newspaper_Carryover),\n             ('Newspaper_saturation', Newspaper_Saturation)\n         ]), ['Newspaper']),\n         ('Web_pipe', Pipeline([\n             ('Web_carryover', Web_Carryover),\n             ('Web_saturation', Web_Saturation)\n         ]), ['Web']),\n        ],\n        remainder='passthrough'\n    )\n    \n    ## 説明変数の変換（adstock）→PLS回帰モデル\n    MMM_pipe = Pipeline([\n        ('adstock', adstock),\n        ('PLS', PLSRegression(n_components))\n    ])\n        \n    #CVによる評価\n    score = cross_val_score(\n        MMM_pipe,\n        X,\n        y,\n        cv=TimeSeriesSplit()\n    )\n    accuracy = score.mean()\n    return accuracy","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 目的関数の最適化を実行する\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective,\n               n_trials=10000,\n               show_progress_bar=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 探索結果\nstudy.best_params","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **パイプライン構築**\n- パイプライン用の、**飽和モデル**と**ラグ効果の2つの変換器クラス**を定義","metadata":{}},{"cell_type":"code","source":"## 飽和モデル\nclass Saturation(BaseEstimator, TransformerMixin):\n    \n    # 初期化\n    def __init__(self,func='exp',a=1.0,K=1.0,m=100.0,b=1.0, c=0.1):\n        self.func = func\n        self.a = a\n        self.K = K\n        self.m = m\n        self.b = b\n        self.c = c\n    \n    # 学習\n    def fit(self, X, y=None):\n        return self\n    \n    # 処理（入力→出力）\n    def transform(self, X):\n        if self.func == 'exp':\n            X_ = exp_Saturation(X,\n                                self.a\n                               ).reshape(-1,1)\n        elif self.func == \"logit\":\n            X_ = logit_Saturation(X,\n                                  self.K, \n                                  self.b,\n                                  self.c, \n                                  self.m\n                                 ).reshape(-1,1)\n        else:\n            X_ = gom_Saturation(X,\n                                self.K, \n                                self.b, \n                                self.c, \n                                self.m\n                               ).reshape(-1,1)\n        return X_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## ラグ効果モデル\nclass Carryover(BaseEstimator, TransformerMixin):\n    # 初期化\n    def __init__(self,func='simple',length=4, peak=1, rate=0.5):\n        self.func = func\n        self.length = length\n        self.peak = peak\n        self.rate = rate\n        \n    # 学習        \n    def fit(self, X, y=None):\n        return self\n    # 処理（入力→出力）\n    def transform(self, X):\n        if self.func == 'peak':\n            X_ = peak_Carryover(X, \n                                self.length, \n                                self.peak, \n                                self.rate)  \n        else:\n            X_ = simple_Carryover(X, \n                                  self.rate, \n                                  self.length)\n            \n        return X_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **2つの変換器でアドストック（Ad Stock）**を表現します。これらの**変換器と学習器（PLS回帰モデル）をつなげたパイプラインを構築**","metadata":{}},{"cell_type":"code","source":"## 説明変数の変換部分（adstock）の定義\nadstock = ColumnTransformer(\n    [\n     ('TVCM_pipe', Pipeline([\n                           ('carryover', Carryover()),\n                           ('saturation', Saturation())\n     ]), ['TVCM']),\n     ('Newspaper_pipe', Pipeline([\n                           ('carryover', Carryover()),\n                           ('saturation', Saturation())\n     ]), ['Newspaper']),\n     ('Web_pipe', Pipeline([\n                           ('carryover', Carryover()),\n                           ('saturation', Saturation())\n     ]), ['Web']),\n    ],\n    remainder='passthrough'\n)\n\n## 説明変数の変換（adstock）→PLS回帰モデル（PLS）\nMMM_pipe = Pipeline([\n    ('adstock', adstock),\n    ('PLS', PLSRegression())\n])\n\n## パイプラインの確認\nset_config(display='diagram')   \nMMM_pipe","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **最適ハイパーパラメータで学習**","metadata":{}},{"cell_type":"code","source":"# 最適ハイパーパラメータ\nbest_params={\n 'PLS__n_components': \n    study.best_params.get('n_components'),\n 'adstock__TVCM_pipe__carryover__func': \n    study.best_params.get('TVCM_Carryover_func'),\n 'adstock__TVCM_pipe__carryover__length': \n    study.best_params.get('TVCM_length'),\n 'adstock__TVCM_pipe__carryover__peak': \n    study.best_params.get('TVCM_peak'),\n 'adstock__TVCM_pipe__carryover__rate': \n    study.best_params.get('TVCM_rate'),\n 'adstock__TVCM_pipe__saturation__func': \n    study.best_params.get('TVCM_Saturation_func'),\n 'adstock__TVCM_pipe__saturation__a': \n    study.best_params.get('TVCM_a'),\n 'adstock__TVCM_pipe__saturation__K': \n    study.best_params.get('TVCM_K'),\n 'adstock__TVCM_pipe__saturation__m': \n    study.best_params.get('TVCM_m'),\n 'adstock__TVCM_pipe__saturation__b': \n    study.best_params.get('TVCM_b'),\n 'adstock__TVCM_pipe__saturation__c': \n    study.best_params.get('TVCM_c'),\n 'adstock__Newspaper_pipe__carryover__func': \n    study.best_params.get('Newspaper_Carryover_func'),\n 'adstock__Newspaper_pipe__carryover__length': \n    study.best_params.get('Newspaper_length'),\n 'adstock__Newspaper_pipe__carryover__peak': \n    study.best_params.get('Newspaper_peak'),\n 'adstock__Newspaper_pipe__carryover__rate': \n    study.best_params.get('Newspaper_rate'),\n 'adstock__Newspaper_pipe__saturation__func': \n    study.best_params.get('Newspaper_Saturation_func'),\n 'adstock__Newspaper_pipe__saturation__a': \n    study.best_params.get('Newspaper_a'),\n 'adstock__Newspaper_pipe__saturation__K': \n    study.best_params.get('Newspaper_K'),\n 'adstock__Newspaper_pipe__saturation__m': \n    study.best_params.get('Newspaper_m'),\n 'adstock__Newspaper_pipe__saturation__b': \n    study.best_params.get('Newspaper_b'),\n 'adstock__Newspaper_pipe__saturation__c': \n    study.best_params.get('Newspaper_c'),\n 'adstock__Web_pipe__carryover__func':\n    study.best_params.get('Web_Carryover_func'),\n 'adstock__Web_pipe__carryover__length': \n    study.best_params.get('Web_length'),\n 'adstock__Web_pipe__carryover__peak': \n    study.best_params.get('Web_peak'),\n 'adstock__Web_pipe__carryover__rate': \n    study.best_params.get('Web_rate'),\n 'adstock__Web_pipe__saturation__func': \n    study.best_params.get('Web_Saturation_func'),\n 'adstock__Web_pipe__saturation__a': \n    study.best_params.get('Web_a'),\n 'adstock__Web_pipe__saturation__K': \n    study.best_params.get('Web_K'),\n 'adstock__Web_pipe__saturation__m': \n    study.best_params.get('Web_m'),\n 'adstock__Web_pipe__saturation__b': \n    study.best_params.get('Web_b'),\n 'adstock__Web_pipe__saturation__c': \n    study.best_params.get('Web_c'),\n}\n\n# パイプラインのインスタンス\nMMM_pipe_best = MMM_pipe.set_params(**best_params)\n\n# 全データで学習\nMMM_pipe_best.fit(X, y)\n\n# R2（決定係数）\nMMM_pipe_best.score(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **予測の実施**","metadata":{}},{"cell_type":"code","source":"# 予測の実施\n# \n# 目的変数y（売上）の予測\npred = pd.DataFrame(MMM_pipe_best.predict(X),\n                    index=X.index,\n                    columns=['y'])\n# 各媒体による売上の予測\n## 値がすべて0の説明変数\nX_ = X.copy()\nX_.iloc[:,:]=0\n## Base\npred['Base'] = MMM_pipe_best.predict(X_)\n## 媒体\nfor i in range(len(X.columns)):\n    X_.iloc[:,:]=0\n    X_.iloc[:,i]=X.iloc[:,i]\n    pred[X.columns[i]] = MMM_pipe_best.predict(X_)[:,0]-pred['Base']\n    \nprint(pred) #確認\n\n# グラフ化（実測値と予測値）\n## 散布図を描画\nplt.scatter(y,pred['y'])\nplt.title('R2:'+str(round(MMM_pipe_best.score(X, y),4)))\nplt.ylabel('pred')\nplt.xlabel('actual')\nplt.show()\n## 折れ線グラフ（時系列推移）\nfig, ax = plt.subplots()\nax.plot(y.index, y.values, label=\"actual\")\nax.plot(y.index, pred['y'].values, label=\"pred\", linestyle=\"dotted\", lw=2) \nax.set_ylim(0, 4e6)\nplt.legend()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **貢献度とマーケティングROIの算定**","metadata":{}},{"cell_type":"code","source":"# 貢献度\n\n# 予測値の補正\ncorrection_factor = y.div(pred['y'], axis=0)   #補正係数\npred_adj = pred.mul(correction_factor, axis=0) #補正後の予測値\n\n# 各媒体の貢献度だけ抽出\ncontribution = pred_adj[['Base', 'Web', 'Newspaper', 'TVCM']]\nprint(contribution.head())\n\n# グラフ化\nax = (contribution\n      .plot.area(\n          ylabel='Sales',\n          xlabel='Week')\n     )\nhandles, labels = ax.get_legend_handles_labels()\nax.legend(handles[::-1], labels[::-1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 貢献度の構成比\n\n# 媒体別の貢献度の合計\ncontribution_sum = contribution.sum(axis=0)\n# 集計結果の出力\nprint('売上貢献度（円）:\\n', \n      contribution_sum, \n      sep=''\n     )\nprint()\nprint('売上貢献度（構成比）:\\n', \n      contribution_sum/contribution_sum.sum(), \n      sep=''\n     )\n\n# グラフ化\ncontribution_sum.plot.pie(fontsize=24)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# マーケティングROI\n\n# 各媒体のコストの合計\ncost_sum = X.sum(axis=0)\n\n# 各媒体のROIの計算\nROI = (contribution_sum.drop('Base', axis=0) - cost_sum)/cost_sum\nprint('ROI:\\n', ROI, sep='') #確認\n\n# グラフ化\nROI.plot.bar(fontsize=24)","metadata":{},"execution_count":null,"outputs":[]}]}